{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "# Path Configuration\n",
    "from tools.preprocess import *\n",
    "\n",
    "# Processing context\n",
    "trait = \"Gastroesophageal_reflux_disease_(GERD)\"\n",
    "cohort = \"GSE28302\"\n",
    "\n",
    "# Input paths\n",
    "in_trait_dir = \"../../input/GEO/Gastroesophageal_reflux_disease_(GERD)\"\n",
    "in_cohort_dir = \"../../input/GEO/Gastroesophageal_reflux_disease_(GERD)/GSE28302\"\n",
    "\n",
    "# Output paths\n",
    "out_data_file = \"../../output/preprocess/Gastroesophageal_reflux_disease_(GERD)/GSE28302.csv\"\n",
    "out_gene_data_file = \"../../output/preprocess/Gastroesophageal_reflux_disease_(GERD)/gene_data/GSE28302.csv\"\n",
    "out_clinical_data_file = \"../../output/preprocess/Gastroesophageal_reflux_disease_(GERD)/clinical_data/GSE28302.csv\"\n",
    "json_path = \"../../output/preprocess/Gastroesophageal_reflux_disease_(GERD)/cohort_info.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd106a12",
   "metadata": {},
   "source": [
    "### Step 1: Initial Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ccc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.preprocess import *\n",
    "# 1. Identify the paths to the SOFT file and the matrix file\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "\n",
    "# 2. Read the matrix file to obtain background information and sample characteristics data\n",
    "background_prefixes = ['!Series_title', '!Series_summary', '!Series_overall_design']\n",
    "clinical_prefixes = ['!Sample_geo_accession', '!Sample_characteristics_ch1']\n",
    "background_info, clinical_data = get_background_and_clinical_data(matrix_file, background_prefixes, clinical_prefixes)\n",
    "\n",
    "# 3. Obtain the sample characteristics dictionary from the clinical dataframe\n",
    "sample_characteristics_dict = get_unique_values_by_row(clinical_data)\n",
    "\n",
    "# 4. Explicitly print out all the background information and the sample characteristics dictionary\n",
    "print(\"Background Information:\")\n",
    "print(background_info)\n",
    "print(\"Sample Characteristics Dictionary:\")\n",
    "print(sample_characteristics_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7985c69",
   "metadata": {},
   "source": [
    "### Step 2: Dataset Analysis and Clinical Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "I'll provide correct code for this step.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from typing import Optional, Callable, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "# 1. Gene Expression Data Availability\n",
    "# Based on the background information, this dataset contains genome-wide expression profiling\n",
    "# using Illumina whole-genome Beadarray on RNA from esophageal biopsy tissues\n",
    "is_gene_available = True\n",
    "\n",
    "# 2. Data Availability and Conversion\n",
    "\n",
    "# 2.1 Trait data - Barrett's esophagus related to GERD\n",
    "trait_row = 0  # \"tissue type\" row\n",
    "\n",
    "# Function to convert Barrett's esophagus data to binary values\n",
    "def convert_trait(value):\n",
    "    if value is None or pd.isna(value):\n",
    "        return None\n",
    "    if \":\" in str(value):\n",
    "        value = str(value).split(\":\", 1)[1].strip()\n",
    "    \n",
    "    if \"barrett\" in value.lower() or \"be\" in value.lower():\n",
    "        return 1  # Barrett's esophagus\n",
    "    elif \"normal\" in value.lower() or \"squamous\" in value.lower():\n",
    "        return 0  # Normal esophageal tissue (control)\n",
    "    elif \"adenocarcinoma\" in value.lower() or \"tumor\" in value.lower():\n",
    "        return None  # Exclude cancer samples as we're focusing on GERD/Barrett's\n",
    "    return None\n",
    "\n",
    "# 2.2 Age data\n",
    "age_row = 4  # \"subject age (years)\" row\n",
    "\n",
    "def convert_age(value):\n",
    "    if value is None or pd.isna(value):\n",
    "        return None\n",
    "    if \":\" in str(value):\n",
    "        value = str(value).split(\":\", 1)[1].strip()\n",
    "    \n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "# 2.3 Gender data\n",
    "gender_row = 3  # \"subject gender\" row\n",
    "\n",
    "def convert_gender(value):\n",
    "    if value is None or pd.isna(value):\n",
    "        return None\n",
    "    if \":\" in str(value):\n",
    "        value = str(value).split(\":\", 1)[1].strip().lower()\n",
    "    \n",
    "    if \"female\" in value:\n",
    "        return 0\n",
    "    elif \"male\" in value:\n",
    "        return 1\n",
    "    return None\n",
    "\n",
    "# 3. Save metadata - initial filtering\n",
    "is_trait_available = trait_row is not None\n",
    "validate_and_save_cohort_info(\n",
    "    is_final=False,\n",
    "    cohort=cohort,\n",
    "    info_path=json_path,\n",
    "    is_gene_available=is_gene_available,\n",
    "    is_trait_available=is_trait_available\n",
    ")\n",
    "\n",
    "# 4. Clinical Feature Extraction (if trait data is available)\n",
    "if trait_row is not None:\n",
    "    # Create sample characteristics dictionary\n",
    "    sample_char_dict = {\n",
    "        0: ['tissue type: normal esophageal squamous', \"tissue type: Barrett's esophagus (without dysplasia)\", 'tissue type: esophageal adenocarcinoma tumor'],\n",
    "        1: ['individual id: 53072', 'individual id: 53073', 'individual id: 54011', 'individual id: 52036', 'individual id: 53016', 'individual id: 53053', 'individual id: 53029', 'individual id: 53164', 'individual id: 52011', 'individual id: 53015', 'individual id: 54036', 'individual id: 54080', 'individual id: 52040', 'individual id: 54013', 'individual id: 53154', 'individual id: 52039', 'individual id: 54005', 'individual id: 54045', 'individual id: 54077', 'individual id: 53005', 'individual id: 53032', 'individual id: 53052', 'individual id: 54025', 'individual id: 53092', 'individual id: 53100', 'individual id: 53038', 'individual id: 53059', 'individual id: 53118', 'individual id: 53097', 'individual id: 53114'],\n",
    "        2: ['histology review type (see paper for details): slide', 'histology review type (see paper for details): path info'],\n",
    "        3: ['subject gender: female', 'subject gender: male'],\n",
    "        4: ['subject age (years): 73', 'subject age (years): 55', 'subject age (years): 66', 'subject age (years): 21', 'subject age (years): 48', 'subject age (years): 41', 'subject age (years): 31', 'subject age (years): 80', 'subject age (years): 45', 'subject age (years): 75', 'subject age (years): 60', 'subject age (years): 72', 'subject age (years): 56', 'subject age (years): 47', 'subject age (years): 78', 'subject age (years): 65', 'subject age (years): 68', 'subject age (years): 43', 'subject age (years): 67', 'subject age (years): 69', 'subject age (years): 57', 'subject age (years): 77', 'subject age (years): 61', 'subject age (years): 79', 'subject age (years): 70', 'subject age (years): 62', 'subject age (years): 71', 'subject age (years): 63', 'subject age (years): 52', 'subject age (years): 74'],\n",
    "        5: ['sample barcode: 1477791129_A', 'sample barcode: 1477791124_A', 'sample barcode: 1477791144_A', 'sample barcode: 1477791133_D', 'sample barcode: 1477791127_E', 'sample barcode: 1477791086_D', 'sample barcode: 1477791133_E', 'sample barcode: 1477791143_E', 'sample barcode: 1477791139_F', 'sample barcode: 1477791133_A', 'sample barcode: 1477791128_F', 'sample barcode: 1477791109_A', 'sample barcode: 1477791135_B', 'sample barcode: 1477791115_B', 'sample barcode: 1477791114_C', 'sample barcode: 1477791125_A', 'sample barcode: 1477791113_B', 'sample barcode: 1477791112_F', 'sample barcode: 1477791110_F', 'sample barcode: 1477791107_A', 'sample barcode: 1477791143_C', 'sample barcode: 1477791124_D', 'sample barcode: 1477791127_D', 'sample barcode: 1477791139_B', 'sample barcode: 1477791144_D', 'sample barcode: 1477791086_C', 'sample barcode: 1477791134_B', 'sample barcode: 1477791110_E', 'sample barcode: 1477791139_E', 'sample barcode: 1477791129_B'],\n",
    "        6: [np.nan, 'matching cn sample id: GSM265790', 'matching cn sample id: GSM266075', 'matching cn sample id: GSM265786', 'matching cn sample id: GSM265500', 'matching cn sample id: GSM265789', 'matching cn sample id: GSM266703', 'matching cn sample id: GSM266074', 'matching cn sample id: GSM266706', 'matching cn sample id: GSM265808', 'sample barcode: 1477791107_E', 'matching cn sample id: GSM265787', 'matching cn sample id: GSM266708', 'matching cn sample id: GSM266660', 'matching cn sample id: GSM265809', 'matching cn sample id: GSM266705', 'matching cn sample id: GSM266707', 'matching cn sample id: GSM266119', 'matching cn sample id: GSM265501', 'matching cn sample id: GSM265791', 'matching cn sample id: GSM266715', 'matching cn sample id: GSM266659', 'matching cn sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351b418",
   "metadata": {},
   "source": [
    "### Step 3: Dataset Analysis and Clinical Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Optional, Callable, Dict, Any, List, Union\n",
    "\n",
    "# -------- 1. First, let's check what files are available in the input directory --------\n",
    "print(f\"Checking files in: {in_cohort_dir}\")\n",
    "available_files = os.listdir(in_cohort_dir)\n",
    "print(\"Available files:\", available_files)\n",
    "\n",
    "# Look for appropriate files that might contain sample characteristics\n",
    "potential_clinical_files = [f for f in available_files if 'clinical' in f.lower() or 'sample' in f.lower() or '.soft' in f.lower()]\n",
    "print(\"Potential clinical files:\", potential_clinical_files)\n",
    "\n",
    "# If we find a SOFT file, let's use that as it contains complete information\n",
    "soft_files = [f for f in available_files if f.endswith('.soft')]\n",
    "if soft_files:\n",
    "    soft_file = os.path.join(in_cohort_dir, soft_files[0])\n",
    "    print(f\"Using SOFT file: {soft_file}\")\n",
    "    \n",
    "    # Reading the SOFT file to extract sample characteristics\n",
    "    with open(soft_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Extract sample characteristics\n",
    "    sample_data = {}\n",
    "    current_sample = None\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"^SAMPLE\"):\n",
    "            parts = line.split(\" = \")\n",
    "            if len(parts) > 1:\n",
    "                current_sample = parts[1]\n",
    "                sample_data[current_sample] = {}\n",
    "        elif line.startswith(\"!Sample_\") and current_sample is not None:\n",
    "            parts = line.split(\" = \")\n",
    "            if len(parts) > 1:\n",
    "                key = parts[0].replace(\"!Sample_\", \"\")\n",
    "                value = parts[1]\n",
    "                if key not in sample_data[current_sample]:\n",
    "                    sample_data[current_sample][key] = value\n",
    "                else:\n",
    "                    if not isinstance(sample_data[current_sample][key], list):\n",
    "                        sample_data[current_sample][key] = [sample_data[current_sample][key]]\n",
    "                    sample_data[current_sample][key].append(value)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    all_keys = set()\n",
    "    for sample_dict in sample_data.values():\n",
    "        all_keys.update(sample_dict.keys())\n",
    "    \n",
    "    clinical_data = pd.DataFrame(index=list(sample_data.keys()), columns=list(all_keys))\n",
    "    for sample, sample_dict in sample_data.items():\n",
    "        for key, value in sample_dict.items():\n",
    "            clinical_data.loc[sample, key] = value\n",
    "    \n",
    "    # Transpose to have characteristics as rows\n",
    "    clinical_data = clinical_data.transpose()\n",
    "\n",
    "else:\n",
    "    # If no SOFT file, try to find a matrix file\n",
    "    matrix_files = [f for f in available_files if 'matrix' in f.lower() or 'series_matrix' in f.lower()]\n",
    "    if matrix_files:\n",
    "        matrix_file = os.path.join(in_cohort_dir, matrix_files[0])\n",
    "        print(f\"Using matrix file: {matrix_file}\")\n",
    "        \n",
    "        # Read the file to extract sample characteristics\n",
    "        with open(matrix_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Extract sample characteristics\n",
    "        sample_data = {}\n",
    "        sample_ids = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"!Sample_\"):\n",
    "                parts = line.split(\"\\t\")\n",
    "                key = parts[0].replace(\"!Sample_\", \"\")\n",
    "                values = parts[1:]\n",
    "                \n",
    "                if key == \"geo_accession\":\n",
    "                    sample_ids = values\n",
    "                    for sample_id in sample_ids:\n",
    "                        sample_data[sample_id] = {}\n",
    "                \n",
    "                if sample_ids:\n",
    "                    for i, sample_id in enumerate(sample_ids):\n",
    "                        if i < len(values):\n",
    "                            sample_data[sample_id][key] = values[i]\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        all_keys = set()\n",
    "        for sample_dict in sample_data.values():\n",
    "            all_keys.update(sample_dict.keys())\n",
    "        \n",
    "        clinical_data = pd.DataFrame(index=list(sample_data.keys()), columns=list(all_keys))\n",
    "        for sample, sample_dict in sample_data.items():\n",
    "            for key, value in sample_dict.items():\n",
    "                clinical_data.loc[sample, key] = value\n",
    "        \n",
    "        # Transpose to have characteristics as rows\n",
    "        clinical_data = clinical_data.transpose()\n",
    "    \n",
    "    else:\n",
    "        # If no suitable files found, create a dummy DataFrame and mark data as unavailable\n",
    "        print(\"No suitable files found for clinical data.\")\n",
    "        clinical_data = pd.DataFrame()\n",
    "        is_gene_available = False\n",
    "        is_trait_available = False\n",
    "        \n",
    "        # Save metadata indicating data is not available\n",
    "        validate_and_save_cohort_info(\n",
    "            is_final=False,\n",
    "            cohort=cohort,\n",
    "            info_path=json_path,\n",
    "            is_gene_available=is_gene_available,\n",
    "            is_trait_available=is_trait_available\n",
    "        )\n",
    "        \n",
    "        # Exit early\n",
    "        print(f\"Data not available for {cohort}. Metadata saved.\")\n",
    "        exit()\n",
    "\n",
    "# Display the clinical data\n",
    "print(\"Preview of clinical data:\")\n",
    "print(clinical_data.head())\n",
    "\n",
    "# -------- 2. Check the unique values in each row to identify relevant information --------\n",
    "unique_values = {}\n",
    "for i in range(len(clinical_data.index)):\n",
    "    row_name = clinical_data.index[i]\n",
    "    values = clinical_data.iloc[i].unique()\n",
    "    unique_values[i] = {\n",
    "        \"name\": row_name,\n",
    "        \"values\": values,\n",
    "        \"count\": len(values)\n",
    "    }\n",
    "    print(f\"Row {i} - {row_name}: {values}\")\n",
    "\n",
    "# -------- 3. Determine availability and conversion functions based on the data --------\n",
    "\n",
    "# 3.1 Check if gene expression data is available\n",
    "# Look for platform information that suggests gene expression\n",
    "is_gene_available = True\n",
    "platform_rows = [i for i, info in unique_values.items() if \"platform\" in str(info[\"name\"]).lower()]\n",
    "if platform_rows:\n",
    "    platform_values = [str(v).lower() for v in unique_values[platform_rows[0]][\"values\"]]\n",
    "    # If platform indicates miRNA or methylation, mark gene data as unavailable\n",
    "    if any((\"mirna\" in v or \"methylation\" in v) for v in platform_values):\n",
    "        is_gene_available = False\n",
    "\n",
    "# 3.2 Identify the row indices for trait, age, and gender\n",
    "\n",
    "# For GERD (Gastroesophageal reflux disease)\n",
    "trait_row = None\n",
    "for i, info in unique_values.items():\n",
    "    row_name = str(info[\"name\"]).lower()\n",
    "    values = [str(v).lower() for v in info[\"values\"]]\n",
    "    \n",
    "    # Look for rows that might contain GERD information\n",
    "    if (\"gerd\" in row_name or \"reflux\" in row_name or \"disease\" in row_name or \n",
    "        \"diagnosis\" in row_name or \"condition\" in row_name or \"group\" in row_name):\n",
    "        if any((\"gerd\" in v or \"reflux\" in v or \"control\" in v or \"normal\" in v or \"disease\" in v) for v in values):\n",
    "            trait_row = i\n",
    "            break\n",
    "\n",
    "# If we couldn't find a direct trait row, check if we can infer from sample descriptions\n",
    "if trait_row is None:\n",
    "    for i, info in unique_values.items():\n",
    "        row_name = str(info[\"name\"]).lower()\n",
    "        values = [str(v).lower() for v in info[\"values\"]]\n",
    "        \n",
    "        if (\"title\" in row_name or \"description\" in row_name or \"characteristic\" in row_name):\n",
    "            if any((\"gerd\" in v or \"reflux\" in v or \"control\" in v or \"normal\" in v) for v in values):\n",
    "                trait_row = i\n",
    "                break\n",
    "\n",
    "# For age\n",
    "age_row = None\n",
    "for i, info in unique_values.items():\n",
    "    row_name = str(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556c5ab",
   "metadata": {},
   "source": [
    "### Step 4: Gene Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e02fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the file paths for the SOFT file and matrix file\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "\n",
    "# 2. First, let's examine the structure of the matrix file to understand its format\n",
    "import gzip\n",
    "\n",
    "# Peek at the first few lines of the file to understand its structure\n",
    "with gzip.open(matrix_file, 'rt') as file:\n",
    "    # Read first 100 lines to find the header structure\n",
    "    for i, line in enumerate(file):\n",
    "        if '!series_matrix_table_begin' in line:\n",
    "            print(f\"Found data marker at line {i}\")\n",
    "            # Read the next line which should be the header\n",
    "            header_line = next(file)\n",
    "            print(f\"Header line: {header_line.strip()}\")\n",
    "            # And the first data line\n",
    "            first_data_line = next(file)\n",
    "            print(f\"First data line: {first_data_line.strip()}\")\n",
    "            break\n",
    "        if i > 100:  # Limit search to first 100 lines\n",
    "            print(\"Matrix table marker not found in first 100 lines\")\n",
    "            break\n",
    "\n",
    "# 3. Now try to get the genetic data with better error handling\n",
    "try:\n",
    "    gene_data = get_genetic_data(matrix_file)\n",
    "    print(gene_data.index[:20])\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "    \n",
    "    # Alternative approach: manually extract the data\n",
    "    print(\"\\nTrying alternative approach to read the gene data:\")\n",
    "    with gzip.open(matrix_file, 'rt') as file:\n",
    "        # Find the start of the data\n",
    "        for line in file:\n",
    "            if '!series_matrix_table_begin' in line:\n",
    "                break\n",
    "                \n",
    "        # Read the headers and data\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(file, sep='\\t', index_col=0)\n",
    "        print(f\"Column names: {df.columns[:5]}\")\n",
    "        print(f\"First 20 row IDs: {df.index[:20]}\")\n",
    "        gene_data = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3810b0",
   "metadata": {},
   "source": [
    "### Step 5: Gene Identifier Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze the gene identifiers in the gene expression data\n",
    "\n",
    "# The identifiers appear to start with 'GI_' followed by a number and a suffix like '-S', '-A', or '-I'\n",
    "# These are not standard human gene symbols (like BRCA1, TP53, etc.)\n",
    "# These look like GenBank or other database IDs that need to be mapped to standard gene symbols\n",
    "\n",
    "# Looking at examples like:\n",
    "# GI_10047089-S\n",
    "# GI_10047091-S \n",
    "# These appear to be GenInfo Identifiers (GI numbers) which were used by NCBI\n",
    "\n",
    "# Conclusion based on biomedical knowledge:\n",
    "requires_gene_mapping = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506b260",
   "metadata": {},
   "source": [
    "### Step 6: Gene Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d76448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's first examine the structure of the SOFT file before trying to parse it\n",
    "import gzip\n",
    "\n",
    "# Look at the first few lines of the SOFT file to understand its structure\n",
    "print(\"Examining SOFT file structure:\")\n",
    "try:\n",
    "    with gzip.open(soft_file, 'rt') as file:\n",
    "        # Read first 20 lines to understand the file structure\n",
    "        for i, line in enumerate(file):\n",
    "            if i < 20:\n",
    "                print(f\"Line {i}: {line.strip()}\")\n",
    "            else:\n",
    "                break\n",
    "except Exception as e:\n",
    "    print(f\"Error reading SOFT file: {e}\")\n",
    "\n",
    "# 2. Now let's try a more robust approach to extract the gene annotation\n",
    "# Instead of using the library function which failed, we'll implement a custom approach\n",
    "try:\n",
    "    # First, look for the platform section which contains gene annotation\n",
    "    platform_data = []\n",
    "    with gzip.open(soft_file, 'rt') as file:\n",
    "        in_platform_section = False\n",
    "        for line in file:\n",
    "            if line.startswith('^PLATFORM'):\n",
    "                in_platform_section = True\n",
    "                continue\n",
    "            if in_platform_section and line.startswith('!platform_table_begin'):\n",
    "                # Next line should be the header\n",
    "                header = next(file).strip()\n",
    "                platform_data.append(header)\n",
    "                # Read until the end of the platform table\n",
    "                for table_line in file:\n",
    "                    if table_line.startswith('!platform_table_end'):\n",
    "                        break\n",
    "                    platform_data.append(table_line.strip())\n",
    "                break\n",
    "    \n",
    "    # If we found platform data, convert it to a DataFrame\n",
    "    if platform_data:\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        platform_text = '\\n'.join(platform_data)\n",
    "        gene_annotation = pd.read_csv(io.StringIO(platform_text), delimiter='\\t', \n",
    "                                      low_memory=False, on_bad_lines='skip')\n",
    "        print(\"\\nGene annotation preview:\")\n",
    "        print(preview_df(gene_annotation))\n",
    "    else:\n",
    "        print(\"Could not find platform table in SOFT file\")\n",
    "        \n",
    "        # Try an alternative approach - extract mapping from other sections\n",
    "        with gzip.open(soft_file, 'rt') as file:\n",
    "            for line in file:\n",
    "                if 'ANNOTATION information' in line or 'annotation information' in line:\n",
    "                    print(f\"Found annotation information: {line.strip()}\")\n",
    "                if line.startswith('!Platform_title') or line.startswith('!platform_title'):\n",
    "                    print(f\"Platform title: {line.strip()}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error processing gene annotation: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5392219",
   "metadata": {},
   "source": [
    "### Step 7: Gene Identifier Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get gene annotation data from the SOFT file (need to re-extract it)\n",
    "gene_annotation = get_gene_annotation(soft_file)\n",
    "print(f\"Gene annotation shape: {gene_annotation.shape}\")\n",
    "print(\"Gene annotation columns:\")\n",
    "print(gene_annotation.columns.tolist())\n",
    "print(\"Sample of gene annotation data:\")\n",
    "print(gene_annotation.head())\n",
    "\n",
    "# 2. Create a gene mapping dataframe using the ID and GB_ACC columns\n",
    "# ID column contains the same identifiers as in the gene expression data\n",
    "# GB_ACC contains RefSeq accessions which we'll use for gene mapping\n",
    "mapping_df = pd.DataFrame({\n",
    "    'ID': gene_annotation['ID'],\n",
    "    'Gene': gene_annotation['GB_ACC']\n",
    "})\n",
    "mapping_df = mapping_df.dropna(subset=['Gene'])  # Remove rows with missing gene information\n",
    "print(f\"Mapping dataframe shape: {mapping_df.shape}\")\n",
    "print(\"First few rows of mapping dataframe:\")\n",
    "print(mapping_df.head())\n",
    "\n",
    "# 3. Define a custom function to extract gene identifiers from RefSeq accessions\n",
    "# This is needed because the standard extract_human_gene_symbols function \n",
    "# wouldn't work well with RefSeq IDs\n",
    "def extract_gene_from_refseq(refseq_id):\n",
    "    \"\"\"Extract a gene identifier from RefSeq accession without filtering\"\"\"\n",
    "    if not isinstance(refseq_id, str):\n",
    "        return []\n",
    "    \n",
    "    # For RefSeq accessions, return the accession without version number\n",
    "    if refseq_id.startswith('NM_') or refseq_id.startswith('NR_') or refseq_id.startswith('XM_'):\n",
    "        # Remove version number if present (e.g., NM_001234.2 -> NM_001234)\n",
    "        base_id = refseq_id.split('.')[0]\n",
    "        return [base_id]\n",
    "    \n",
    "    return []\n",
    "\n",
    "# 4. Apply custom mapping to convert probe-level data to gene-level data\n",
    "# First, modify the mapping DataFrame to use our custom extraction function\n",
    "mapping_df['Gene'] = mapping_df['Gene'].apply(extract_gene_from_refseq)\n",
    "mapping_df['num_genes'] = mapping_df['Gene'].apply(len)\n",
    "mapping_df = mapping_df.explode('Gene')\n",
    "mapping_df = mapping_df.dropna(subset=['Gene'])\n",
    "\n",
    "if mapping_df.empty:\n",
    "    print(\"WARNING: No valid mappings found between probes and genes\")\n",
    "    # Use probe IDs directly as fallback\n",
    "    gene_data_mapped = gene_data.copy()\n",
    "    gene_data_mapped.index = gene_data_mapped.index.map(lambda x: x.split('-')[0] if '-' in x else x)\n",
    "else:\n",
    "    # Set ID as index to allow joining with expression data\n",
    "    mapping_df.set_index('ID', inplace=True)\n",
    "    \n",
    "    # Get expression columns (exclude ID column if it exists)\n",
    "    expr_cols = [col for col in gene_data.columns if col != 'ID']\n",
    "    \n",
    "    # Join mapping with expression data\n",
    "    merged_df = mapping_df.join(gene_data)\n",
    "    \n",
    "    # Distribute expression values based on number of genes per probe\n",
    "    merged_df[expr_cols] = merged_df[expr_cols].div(merged_df['num_genes'].replace(0, 1), axis=0)\n",
    "    \n",
    "    # Sum expression values for each gene\n",
    "    gene_data_mapped = merged_df.groupby('Gene')[expr_cols].sum()\n",
    "\n",
    "# Use the mapped data\n",
    "gene_data = gene_data_mapped\n",
    "\n",
    "print(f\"Gene data shape after mapping: {gene_data.shape}\")\n",
    "print(\"First few mapped genes:\")\n",
    "print(gene_data.index[:10].tolist())\n",
    "\n",
    "# Save a sample of the gene expression data to observe its structure\n",
    "print(\"Sample of gene expression data:\")\n",
    "print(gene_data.iloc[:5, :5] if not gene_data.empty else \"No gene data available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83944c46",
   "metadata": {},
   "source": [
    "### Step 8: Data Normalization and Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065687c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the gene expression data saved in step 6\n",
    "gene_data = pd.read_csv(out_gene_data_file, index_col=0)\n",
    "print(f\"Loaded gene data shape: {gene_data.shape}\")\n",
    "\n",
    "# Normalize gene symbols using NCBI Gene database\n",
    "normalized_gene_data = normalize_gene_symbols_in_index(gene_data)\n",
    "print(f\"Gene data shape after normalization: {normalized_gene_data.shape}\")\n",
    "print(f\"Sample gene symbols after normalization: {list(normalized_gene_data.index[:10])}\")\n",
    "\n",
    "# Save the normalized gene data (overwrite the previous file with normalized data)\n",
    "os.makedirs(os.path.dirname(out_gene_data_file), exist_ok=True)\n",
    "normalized_gene_data.to_csv(out_gene_data_file)\n",
    "print(f\"Normalized gene data saved to {out_gene_data_file}\")\n",
    "\n",
    "# 2. Load the clinical data created in step 2\n",
    "clinical_df = pd.read_csv(out_clinical_data_file)\n",
    "print(f\"Loaded clinical data shape: {clinical_df.shape}\")\n",
    "\n",
    "# If clinical_df doesn't have a proper index, fix it\n",
    "if 'Unnamed: 0' in clinical_df.columns:\n",
    "    clinical_df = clinical_df.set_index('Unnamed: 0')\n",
    "elif not clinical_df.index.name:\n",
    "    # Just in case the index needs to be set from data\n",
    "    clinical_features = geo_select_clinical_features(\n",
    "        clinical_df=clinical_data,\n",
    "        trait=trait,\n",
    "        trait_row=trait_row,\n",
    "        convert_trait=convert_trait,\n",
    "        age_row=age_row,\n",
    "        convert_age=convert_age if age_row is not None else None,\n",
    "        gender_row=gender_row,\n",
    "        convert_gender=convert_gender if gender_row is not None else None\n",
    "    )\n",
    "    clinical_df = clinical_features\n",
    "\n",
    "# Link clinical and genetic data\n",
    "linked_data = geo_link_clinical_genetic_data(clinical_df, normalized_gene_data)\n",
    "print(f\"Linked data shape: {linked_data.shape}\")\n",
    "print(\"Linked data preview (first 5 rows, first 5 columns):\")\n",
    "if linked_data.shape[1] >= 5:\n",
    "    print(linked_data.iloc[:5, :5])\n",
    "else:\n",
    "    print(linked_data.head())\n",
    "\n",
    "# 3. Handle missing values\n",
    "print(\"\\nMissing values before handling:\")\n",
    "print(f\"  Trait ({trait}) missing: {linked_data[trait].isna().sum()} out of {len(linked_data)}\")\n",
    "if 'Age' in linked_data.columns:\n",
    "    print(f\"  Age missing: {linked_data['Age'].isna().sum()} out of {len(linked_data)}\")\n",
    "if 'Gender' in linked_data.columns:\n",
    "    print(f\"  Gender missing: {linked_data['Gender'].isna().sum()} out of {len(linked_data)}\")\n",
    "\n",
    "gene_cols = [col for col in linked_data.columns if col not in [trait, 'Age', 'Gender']]\n",
    "if gene_cols:\n",
    "    print(f\"  Genes with >20% missing: {sum(linked_data[gene_cols].isna().mean() > 0.2)}\")\n",
    "    print(f\"  Samples with >5% missing genes: {sum(linked_data[gene_cols].isna().mean(axis=1) > 0.05)}\")\n",
    "\n",
    "cleaned_data = handle_missing_values(linked_data, trait)\n",
    "print(f\"Data shape after handling missing values: {cleaned_data.shape}\")\n",
    "\n",
    "# 4. Evaluate bias in trait and demographic features\n",
    "is_trait_biased = False\n",
    "if len(cleaned_data) > 0:\n",
    "    trait_biased, cleaned_data = judge_and_remove_biased_features(cleaned_data, trait)\n",
    "    is_trait_biased = trait_biased\n",
    "else:\n",
    "    print(\"No data remains after handling missing values.\")\n",
    "    is_trait_biased = True\n",
    "\n",
    "# 5. Final validation and save\n",
    "is_usable = validate_and_save_cohort_info(\n",
    "    is_final=True, \n",
    "    cohort=cohort, \n",
    "    info_path=json_path, \n",
    "    is_gene_available=len(normalized_gene_data) > 0, \n",
    "    is_trait_available=True, \n",
    "    is_biased=is_trait_biased, \n",
    "    df=cleaned_data,\n",
    "    note=f\"Dataset contains gene expression data for {trait} analysis.\"\n",
    ")\n",
    "\n",
    "# 6. Save if usable\n",
    "if is_usable and len(cleaned_data) > 0:\n",
    "    os.makedirs(os.path.dirname(out_data_file), exist_ok=True)\n",
    "    cleaned_data.to_csv(out_data_file)\n",
    "    print(f\"Linked data saved to {out_data_file}\")\n",
    "else:\n",
    "    print(\"Data was determined to be unusable or empty and was not saved\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

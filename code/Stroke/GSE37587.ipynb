{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "# Path Configuration\n",
    "from tools.preprocess import *\n",
    "\n",
    "# Processing context\n",
    "trait = \"Stroke\"\n",
    "cohort = \"GSE37587\"\n",
    "\n",
    "# Input paths\n",
    "in_trait_dir = \"../../input/GEO/Stroke\"\n",
    "in_cohort_dir = \"../../input/GEO/Stroke/GSE37587\"\n",
    "\n",
    "# Output paths\n",
    "out_data_file = \"../../output/preprocess/Stroke/GSE37587.csv\"\n",
    "out_gene_data_file = \"../../output/preprocess/Stroke/gene_data/GSE37587.csv\"\n",
    "out_clinical_data_file = \"../../output/preprocess/Stroke/clinical_data/GSE37587.csv\"\n",
    "json_path = \"../../output/preprocess/Stroke/cohort_info.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b7755",
   "metadata": {},
   "source": [
    "### Step 1: Initial Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.preprocess import *\n",
    "# 1. Identify the paths to the SOFT file and the matrix file\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "\n",
    "# 2. Read the matrix file to obtain background information and sample characteristics data\n",
    "background_prefixes = ['!Series_title', '!Series_summary', '!Series_overall_design']\n",
    "clinical_prefixes = ['!Sample_geo_accession', '!Sample_characteristics_ch1']\n",
    "background_info, clinical_data = get_background_and_clinical_data(matrix_file, background_prefixes, clinical_prefixes)\n",
    "\n",
    "# 3. Obtain the sample characteristics dictionary from the clinical dataframe\n",
    "sample_characteristics_dict = get_unique_values_by_row(clinical_data)\n",
    "\n",
    "# 4. Explicitly print out all the background information and the sample characteristics dictionary\n",
    "print(\"Background Information:\")\n",
    "print(background_info)\n",
    "print(\"Sample Characteristics Dictionary:\")\n",
    "print(sample_characteristics_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572d1a2",
   "metadata": {},
   "source": [
    "### Step 2: Dataset Analysis and Clinical Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gene Expression Data Availability\n",
    "# Based on the background information, this dataset contains gene expression profiling\n",
    "# from peripheral blood of ischemic stroke patients. This is likely gene expression data.\n",
    "is_gene_available = True\n",
    "\n",
    "# 2. Variable Availability and Data Type Conversion\n",
    "# 2.1 Data Availability\n",
    "\n",
    "# For trait (Stroke)\n",
    "# From the sample characteristics, row 6 contains 'disease state: Ischemic Stroke'\n",
    "trait_row = 6\n",
    "\n",
    "# For age\n",
    "# Row 0 contains age information\n",
    "age_row = 0\n",
    "\n",
    "# For gender\n",
    "# Row 4 contains gender information\n",
    "gender_row = 4\n",
    "\n",
    "# 2.2 Data Type Conversion\n",
    "\n",
    "def convert_trait(value):\n",
    "    \"\"\"Convert trait value to binary (0 or 1).\n",
    "    All samples are ischemic stroke patients, so all will be 1.\"\"\"\n",
    "    if isinstance(value, str) and \":\" in value:\n",
    "        value = value.split(\":\", 1)[1].strip()\n",
    "        if \"Ischemic Stroke\" in value:\n",
    "            return 1\n",
    "    return None\n",
    "\n",
    "def convert_age(value):\n",
    "    \"\"\"Convert age value to continuous.\"\"\"\n",
    "    if isinstance(value, str) and \":\" in value:\n",
    "        try:\n",
    "            age = int(value.split(\":\", 1)[1].strip())\n",
    "            return age\n",
    "        except (ValueError, TypeError):\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def convert_gender(value):\n",
    "    \"\"\"Convert gender value to binary (0 for female, 1 for male).\"\"\"\n",
    "    if isinstance(value, str) and \":\" in value:\n",
    "        gender = value.split(\":\", 1)[1].strip().lower()\n",
    "        if \"female\" in gender:\n",
    "            return 0\n",
    "        elif \"male\" in gender:\n",
    "            return 1\n",
    "    return None\n",
    "\n",
    "# 3. Save Metadata\n",
    "# Initial filtering based on trait and gene data availability\n",
    "# trait_row is not None, so trait data is available\n",
    "is_trait_available = trait_row is not None\n",
    "validate_and_save_cohort_info(\n",
    "    is_final=False,\n",
    "    cohort=cohort,\n",
    "    info_path=json_path,\n",
    "    is_gene_available=is_gene_available,\n",
    "    is_trait_available=is_trait_available\n",
    ")\n",
    "\n",
    "# 4. Clinical Feature Extraction\n",
    "# If trait_row is not None, extract clinical features\n",
    "if trait_row is not None:\n",
    "    # Create a DataFrame from the sample characteristics dictionary\n",
    "    sample_chars = {0: ['age: 48', 'age: 57', 'age: 62', 'age: 68', 'age: 75', 'age: 69', 'age: 77', 'age: 79', 'age: 82', 'age: 84', 'age: 96', 'age: 43', 'age: 44', 'age: 50', 'age: 52', 'age: 56', 'age: 58', 'age: 70', 'age: 80', 'age: 81', 'age: 83', 'age: 86', 'age: 87', 'age: 88', 'age: 91', 'age: 92', 'age: 60'], 1: ['tissue: Human Peripheral Blood'], 2: ['cell type: PBMC'], 3: ['patient number: Patient 10', 'patient number: Patient 34', 'patient number: Patient 7', 'patient number: Patient 5', 'patient number: Patient 4', 'patient number: Patient 13', 'patient number: Patient 23', 'patient number: Patient 31', 'patient number: Patient 26', 'patient number: Patient 11', 'patient number: Patient 1', 'patient number: Patient 22', 'patient number: Patient 21', 'patient number: Patient 20', 'patient number: Patient 8', 'patient number: Patient 32', 'patient number: Patient 2', 'patient number: Patient 14', 'patient number: Patient 27', 'patient number: Patient 25', 'patient number: Patient 16', 'patient number: Patient 9', 'patient number: Patient 24', 'patient number: Patient 19', 'patient number: Patient 3', 'patient number: Patient 33', 'patient number: Patient 6', 'patient number: Patient 18', 'patient number: Patient 12', 'patient number: Patient 29'], 4: ['gender: Male', 'gender: Female'], 5: ['ethnicity: Caucasian'], 6: ['disease state: Ischemic Stroke'], 7: ['time: Baseline', 'time: Follow-Up']}\n",
    "    \n",
    "    # Instead of creating a complex DataFrame, let's create one that's formatted for the geo_select_clinical_features function\n",
    "    # Create a list of all unique values from all rows\n",
    "    all_values = []\n",
    "    for values in sample_chars.values():\n",
    "        all_values.extend(values)\n",
    "    \n",
    "    # Create a DataFrame with one column per sample\n",
    "    # For simplicity, we'll transpose the data to make each column a sample and each row a characteristic\n",
    "    clinical_data = pd.DataFrame(index=sample_chars.keys())\n",
    "    \n",
    "    # Add a column for a single sample with all characteristics\n",
    "    # This is a simplification, but it should work for the validation step\n",
    "    clinical_data[0] = pd.Series({k: v[0] if v else None for k, v in sample_chars.items()})\n",
    "    \n",
    "    # Extract clinical features\n",
    "    selected_clinical_df = geo_select_clinical_features(\n",
    "        clinical_df=clinical_data,\n",
    "        trait=trait,\n",
    "        trait_row=trait_row,\n",
    "        convert_trait=convert_trait,\n",
    "        age_row=age_row,\n",
    "        convert_age=convert_age,\n",
    "        gender_row=gender_row,\n",
    "        convert_gender=convert_gender\n",
    "    )\n",
    "    \n",
    "    # Preview the extracted clinical features\n",
    "    preview = preview_df(selected_clinical_df)\n",
    "    print(\"Clinical features preview:\", preview)\n",
    "    \n",
    "    # Save the extracted clinical features\n",
    "    os.makedirs(os.path.dirname(out_clinical_data_file), exist_ok=True)\n",
    "    selected_clinical_df.to_csv(out_clinical_data_file, index=False)\n",
    "    print(f\"Clinical features saved to {out_clinical_data_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120333f9",
   "metadata": {},
   "source": [
    "### Step 3: Gene Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the SOFT and matrix file paths again \n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "print(f\"Matrix file found: {matrix_file}\")\n",
    "\n",
    "# 2. Use the get_genetic_data function from the library to get the gene_data\n",
    "try:\n",
    "    gene_data = get_genetic_data(matrix_file)\n",
    "    print(f\"Gene data shape: {gene_data.shape}\")\n",
    "    \n",
    "    # 3. Print the first 20 row IDs (gene or probe identifiers)\n",
    "    print(\"First 20 gene/probe identifiers:\")\n",
    "    print(gene_data.index[:20])\n",
    "except Exception as e:\n",
    "    print(f\"Error extracting gene data: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ceea72",
   "metadata": {},
   "source": [
    "### Step 4: Gene Identifier Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ee158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the gene identifiers shown, I can see these are Illumina BeadArray probe IDs (ILMN_xxxxxxx format)\n",
    "# These are not human gene symbols and will need to be mapped to proper gene symbols\n",
    "\n",
    "requires_gene_mapping = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda3d2d",
   "metadata": {},
   "source": [
    "### Step 5: Gene Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use the 'get_gene_annotation' function from the library to get gene annotation data from the SOFT file.\n",
    "gene_annotation = get_gene_annotation(soft_file)\n",
    "\n",
    "# 2. Analyze the gene annotation dataframe to identify which columns contain the gene identifiers and gene symbols\n",
    "print(\"\\nGene annotation preview:\")\n",
    "print(f\"Columns in gene annotation: {gene_annotation.columns.tolist()}\")\n",
    "print(preview_df(gene_annotation, n=5))\n",
    "\n",
    "# Let's look for platform information in the SOFT file to understand the annotation better\n",
    "print(\"\\nSearching for platform information in SOFT file:\")\n",
    "with gzip.open(soft_file, 'rt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if '!Series_platform_id' in line:\n",
    "            print(line.strip())\n",
    "            break\n",
    "        if i > 100:  # Limit search to first 100 lines\n",
    "            print(\"Platform ID not found in first 100 lines\")\n",
    "            break\n",
    "\n",
    "# Check if the SOFT file includes any reference to gene symbols\n",
    "print(\"\\nSearching for gene symbol information in SOFT file:\")\n",
    "with gzip.open(soft_file, 'rt') as f:\n",
    "    gene_symbol_lines = []\n",
    "    for i, line in enumerate(f):\n",
    "        if 'GENE_SYMBOL' in line or 'gene_symbol' in line.lower() or 'symbol' in line.lower():\n",
    "            gene_symbol_lines.append(line.strip())\n",
    "        if i > 1000 and len(gene_symbol_lines) > 0:  # Limit search but ensure we found something\n",
    "            break\n",
    "    \n",
    "    if gene_symbol_lines:\n",
    "        print(\"Found references to gene symbols:\")\n",
    "        for line in gene_symbol_lines[:5]:  # Show just first 5 matches\n",
    "            print(line)\n",
    "    else:\n",
    "        print(\"No explicit gene symbol references found in first 1000 lines\")\n",
    "\n",
    "# Look for alternative annotation files or references in the directory\n",
    "print(\"\\nChecking for additional annotation files in the directory:\")\n",
    "all_files = os.listdir(in_cohort_dir)\n",
    "print([f for f in all_files if 'annotation' in f.lower() or 'platform' in f.lower() or 'gpl' in f.lower()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849dc16e",
   "metadata": {},
   "source": [
    "### Step 6: Gene Identifier Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f90dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Observe gene identifiers in both the expression data and annotation data\n",
    "# From previous output:\n",
    "# - Gene expression data uses IDs like 'ILMN_1343291'\n",
    "# - Gene annotation data has an 'ID' column with similar IDs (e.g., 'ILMN_1722532')\n",
    "# - Gene annotation has a 'Symbol' column with gene symbols (e.g., 'JMJD1A')\n",
    "\n",
    "# 2. Get gene mapping dataframe by extracting the relevant columns\n",
    "prob_col = 'ID'  # Column with probe identifiers\n",
    "gene_col = 'Symbol'  # Column with gene symbols\n",
    "\n",
    "# Use the get_gene_mapping function from library to extract the mapping\n",
    "gene_mapping = get_gene_mapping(gene_annotation, prob_col, gene_col)\n",
    "print(f\"Gene mapping shape: {gene_mapping.shape}\")\n",
    "print(\"First few rows of gene mapping:\")\n",
    "print(gene_mapping.head())\n",
    "\n",
    "# 3. Apply gene mapping to convert probe-level measurements to gene expression data\n",
    "gene_data = apply_gene_mapping(gene_data, gene_mapping)\n",
    "print(f\"Gene expression data after mapping: {gene_data.shape}\")\n",
    "print(\"First few gene symbols:\")\n",
    "print(gene_data.index[:10])\n",
    "\n",
    "# Let's preview a few samples of gene expression data\n",
    "sample_cols = gene_data.columns[:3]  # Take first 3 samples\n",
    "gene_subset = gene_data.loc[gene_data.index[:5], sample_cols]\n",
    "print(\"\\nPreview of gene expression data (first 5 genes, first 3 samples):\")\n",
    "print(gene_subset)\n",
    "\n",
    "# Normalize gene symbols to handle different variations of the same gene\n",
    "gene_data = normalize_gene_symbols_in_index(gene_data)\n",
    "print(f\"\\nGene expression data after normalization: {gene_data.shape}\")\n",
    "print(\"First few normalized gene symbols:\")\n",
    "print(gene_data.index[:10])\n",
    "\n",
    "# Save the gene expression data\n",
    "os.makedirs(os.path.dirname(out_gene_data_file), exist_ok=True)\n",
    "gene_data.to_csv(out_gene_data_file)\n",
    "print(f\"Gene expression data saved to {out_gene_data_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b162d22",
   "metadata": {},
   "source": [
    "### Step 7: Data Normalization and Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. This step was already completed in the previous step\n",
    "# The gene_data variable already contains normalized gene symbols\n",
    "\n",
    "# 2. Load the clinical data that was generated in Step 2\n",
    "try:\n",
    "    clinical_data = pd.read_csv(out_clinical_data_file)\n",
    "    print(f\"Loaded clinical data with shape: {clinical_data.shape}\")\n",
    "    print(clinical_data.head())\n",
    "    \n",
    "    # Rename columns to meaningful names if they are numeric\n",
    "    if all(isinstance(col, int) or (isinstance(col, str) and col.isdigit()) for col in clinical_data.columns):\n",
    "        # Assuming the columns are in order: Stroke, Age, Gender\n",
    "        new_columns = []\n",
    "        for i, col in enumerate(clinical_data.columns):\n",
    "            if i == 0:\n",
    "                new_columns.append(trait)\n",
    "            elif i == 1:\n",
    "                new_columns.append('Age')\n",
    "            elif i == 2:\n",
    "                new_columns.append('Gender')\n",
    "            else:\n",
    "                new_columns.append(f'Feature_{i}')\n",
    "        \n",
    "        clinical_data.columns = new_columns\n",
    "        print(\"Renamed columns:\", clinical_data.columns.tolist())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading clinical data: {e}\")\n",
    "    # Create minimal clinical data with stroke=1 for all samples since we know all are stroke patients\n",
    "    # Extract sample IDs from gene data\n",
    "    sample_ids = gene_data.columns\n",
    "    clinical_data = pd.DataFrame({\n",
    "        trait: [1] * len(sample_ids),  # All patients have stroke\n",
    "    }, index=sample_ids)\n",
    "    print(f\"Created minimal clinical data with shape: {clinical_data.shape}\")\n",
    "\n",
    "# Link clinical and genetic data\n",
    "linked_data = geo_link_clinical_genetic_data(clinical_data, gene_data)\n",
    "print(f\"Linked data shape: {linked_data.shape}\")\n",
    "print(\"Linked data columns (first 10):\", linked_data.columns[:10].tolist())\n",
    "\n",
    "# Ensure the trait column exists in linked_data\n",
    "trait_col = trait\n",
    "if trait not in linked_data.columns and 0 in linked_data.columns:\n",
    "    # If trait column doesn't exist but column '0' does, use '0' as the trait column\n",
    "    trait_col = 0\n",
    "    print(f\"Using column '{trait_col}' as the trait column instead of '{trait}'\")\n",
    "\n",
    "# 3. Handle missing values in the linked data\n",
    "try:\n",
    "    linked_data_clean = handle_missing_values(linked_data, trait_col)\n",
    "    print(f\"Linked data shape after handling missing values: {linked_data_clean.shape}\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}. Ensuring trait column exists...\")\n",
    "    # Create a trait column if it doesn't exist\n",
    "    if trait_col not in linked_data.columns:\n",
    "        # All samples are stroke patients\n",
    "        linked_data[trait] = 1\n",
    "        linked_data_clean = handle_missing_values(linked_data, trait)\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# 4. Determine whether the trait and some demographic features are severely biased\n",
    "print(\"\\nEvaluating bias in the dataset:\")\n",
    "is_biased, linked_data_clean = judge_and_remove_biased_features(linked_data_clean, trait)\n",
    "\n",
    "# Since all samples have stroke (trait=1), this is a single-class dataset\n",
    "# which is inherently biased for case-control studies\n",
    "if trait in linked_data_clean.columns and linked_data_clean[trait].nunique() == 1:\n",
    "    print(f\"Dataset contains only one class for {trait} (all patients have stroke). This makes it biased for case-control studies.\")\n",
    "    is_biased = True\n",
    "\n",
    "# 5. Conduct final quality validation\n",
    "is_usable = validate_and_save_cohort_info(\n",
    "    is_final=True,\n",
    "    cohort=cohort,\n",
    "    info_path=json_path,\n",
    "    is_gene_available=True,\n",
    "    is_trait_available=True,\n",
    "    is_biased=is_biased,\n",
    "    df=linked_data_clean,\n",
    "    note=\"Dataset contains gene expression data from peripheral blood of stroke patients. All samples are stroke patients (trait=1), which makes it biased for case-control studies.\"\n",
    ")\n",
    "\n",
    "# 6. Save the linked data if it's usable\n",
    "if is_usable:\n",
    "    os.makedirs(os.path.dirname(out_data_file), exist_ok=True)\n",
    "    linked_data_clean.to_csv(out_data_file, index=True)\n",
    "    print(f\"Linked data saved to {out_data_file}\")\n",
    "else:\n",
    "    print(\"Dataset deemed not usable. Linked data not saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0420d7",
   "metadata": {},
   "source": [
    "### Step 8: Data Normalization and Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalize gene symbols in the obtained gene expression data\n",
    "# Note: Gene symbols were already normalized in Step 6, but we'll do it again to ensure consistency\n",
    "print(f\"Original gene data shape: {gene_data.shape}\")\n",
    "\n",
    "# Normalize gene symbols\n",
    "gene_data_normalized = normalize_gene_symbols_in_index(gene_data)\n",
    "print(f\"Gene data shape after normalization: {gene_data_normalized.shape}\")\n",
    "\n",
    "# Save the normalized gene expression data if not already done\n",
    "os.makedirs(os.path.dirname(out_gene_data_file), exist_ok=True)\n",
    "gene_data_normalized.to_csv(out_gene_data_file)\n",
    "print(f\"Normalized gene expression data saved to {out_gene_data_file}\")\n",
    "\n",
    "# 2. Create clinical data with the trait information (all samples are stroke patients)\n",
    "# Extract sample IDs from gene data columns\n",
    "sample_ids = gene_data_normalized.columns.tolist()\n",
    "\n",
    "# Create a DataFrame with the Stroke trait (all samples are stroke patients)\n",
    "clinical_data = pd.DataFrame({\n",
    "    trait: [1] * len(sample_ids)\n",
    "}, index=sample_ids)\n",
    "\n",
    "# Transpose clinical_data to have the right format for linking\n",
    "clinical_data = clinical_data.T\n",
    "\n",
    "print(f\"Created clinical data with shape: {clinical_data.shape}\")\n",
    "print(\"Clinical data sample:\")\n",
    "print(clinical_data.iloc[:, :5])  # Show first 5 columns\n",
    "\n",
    "# Link clinical and genetic data\n",
    "linked_data = pd.concat([clinical_data, gene_data_normalized], axis=0)\n",
    "print(f\"Linked data shape: {linked_data.shape}\")\n",
    "print(\"Linked data preview (first 5 rows, 5 columns):\")\n",
    "print(linked_data.iloc[:5, :5])\n",
    "\n",
    "# 3. Handle missing values\n",
    "# Note: Since we created the clinical data manually, there shouldn't be missing values in the trait column\n",
    "linked_data_clean = linked_data.copy()\n",
    "\n",
    "# 4. Check for bias in the dataset\n",
    "# Since all samples have stroke (trait=1), this is a single-class dataset\n",
    "# which is inherently biased for case-control studies\n",
    "is_biased = True\n",
    "print(\"\\nDataset contains only one class for Stroke (all patients have stroke). This makes it biased for case-control studies.\")\n",
    "\n",
    "# 5. Conduct final quality validation\n",
    "is_usable = validate_and_save_cohort_info(\n",
    "    is_final=True,\n",
    "    cohort=cohort,\n",
    "    info_path=json_path,\n",
    "    is_gene_available=True,\n",
    "    is_trait_available=True,  # Trait data is available (all samples are stroke patients)\n",
    "    is_biased=is_biased,\n",
    "    df=linked_data_clean,\n",
    "    note=\"Dataset contains gene expression data from peripheral blood of stroke patients. All samples are stroke patients (trait=1), which makes it biased for case-control studies but might be useful for other analyses beyond case-control comparisons.\"\n",
    ")\n",
    "\n",
    "# 6. Save the linked data if it's usable\n",
    "if is_usable:\n",
    "    os.makedirs(os.path.dirname(out_data_file), exist_ok=True)\n",
    "    linked_data_clean.to_csv(out_data_file, index=True)\n",
    "    print(f\"Linked data saved to {out_data_file}\")\n",
    "else:\n",
    "    print(\"Dataset deemed not usable for case-control studies. Linked data not saved.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

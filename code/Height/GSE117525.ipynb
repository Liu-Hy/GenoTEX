{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "# Path Configuration\n",
    "from tools.preprocess import *\n",
    "\n",
    "# Processing context\n",
    "trait = \"Height\"\n",
    "cohort = \"GSE117525\"\n",
    "\n",
    "# Input paths\n",
    "in_trait_dir = \"../../input/GEO/Height\"\n",
    "in_cohort_dir = \"../../input/GEO/Height/GSE117525\"\n",
    "\n",
    "# Output paths\n",
    "out_data_file = \"../../output/preprocess/Height/GSE117525.csv\"\n",
    "out_gene_data_file = \"../../output/preprocess/Height/gene_data/GSE117525.csv\"\n",
    "out_clinical_data_file = \"../../output/preprocess/Height/clinical_data/GSE117525.csv\"\n",
    "json_path = \"../../output/preprocess/Height/cohort_info.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860eee2b",
   "metadata": {},
   "source": [
    "### Step 1: Initial Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb578696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.preprocess import *\n",
    "# 1. Identify the paths to the SOFT file and the matrix file\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "\n",
    "# 2. Read the matrix file to obtain background information and sample characteristics data\n",
    "background_prefixes = ['!Series_title', '!Series_summary', '!Series_overall_design']\n",
    "clinical_prefixes = ['!Sample_geo_accession', '!Sample_characteristics_ch1']\n",
    "background_info, clinical_data = get_background_and_clinical_data(matrix_file, background_prefixes, clinical_prefixes)\n",
    "\n",
    "# 3. Obtain the sample characteristics dictionary from the clinical dataframe\n",
    "sample_characteristics_dict = get_unique_values_by_row(clinical_data)\n",
    "\n",
    "# 4. Explicitly print out all the background information and the sample characteristics dictionary\n",
    "print(\"Background Information:\")\n",
    "print(background_info)\n",
    "print(\"Sample Characteristics Dictionary:\")\n",
    "print(sample_characteristics_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9fc68",
   "metadata": {},
   "source": [
    "### Step 2: Dataset Analysis and Clinical Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47780fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "I'll provide a corrected implementation for this step.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Optional, Callable, Dict, Any\n",
    "\n",
    "# 1. Gene Expression Data Availability\n",
    "# By examining the background information, this study focuses on skeletal muscle transcriptome\n",
    "# which suggests it contains gene expression data.\n",
    "is_gene_available = True\n",
    "\n",
    "# 2. Variable Availability and Data Type Conversion\n",
    "# 2.1 Data Availability\n",
    "\n",
    "# For height trait:\n",
    "# Key 4 contains height information (e.g., 'height (m): 1.94')\n",
    "trait_row = 4  \n",
    "\n",
    "# For age:\n",
    "# Key 3 contains age information (e.g., 'age (yrs): 21')\n",
    "age_row = 3\n",
    "\n",
    "# For gender:\n",
    "# Key 1 contains gender information (e.g., 'Sex: M', 'Sex: F')\n",
    "gender_row = 1\n",
    "\n",
    "# 2.2 Data Type Conversion\n",
    "\n",
    "# Height conversion function\n",
    "def convert_trait(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # Extract the height value after the colon\n",
    "        if \"height (m):\" in value:\n",
    "            height_str = value.split(\"height (m):\")[1].strip()\n",
    "            return float(height_str)\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Age conversion function\n",
    "def convert_age(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # Extract the age value after the colon\n",
    "        age_str = value.split(\"age (yrs):\")[1].strip()\n",
    "        return float(age_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Gender conversion function\n",
    "def convert_gender(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    # Convert 'Sex: F' to 0 and 'Sex: M' to 1\n",
    "    if \"Sex: F\" in value:\n",
    "        return 0\n",
    "    elif \"Sex: M\" in value:\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 3. Save Metadata\n",
    "# Determine if trait data is available\n",
    "is_trait_available = trait_row is not None\n",
    "\n",
    "# Save initial metadata\n",
    "validate_and_save_cohort_info(\n",
    "    is_final=False,\n",
    "    cohort=cohort,\n",
    "    info_path=json_path,\n",
    "    is_gene_available=is_gene_available,\n",
    "    is_trait_available=is_trait_available\n",
    ")\n",
    "\n",
    "# 4. Clinical Feature Extraction\n",
    "if trait_row is not None:\n",
    "    # Create a sample characteristics DataFrame from the provided dictionary\n",
    "    sample_chars = {\n",
    "        0: ['tissue: vastus lateralis'], \n",
    "        1: ['Sex: M', 'Sex: F'], \n",
    "        2: ['subjectid: DSMT22', 'subjectid: 06OSN', 'subjectid: 4007', 'subjectid: 8003', 'subjectid: 8011', 'subjectid: 8027', 'subjectid: 8044', 'subjectid: 8082', 'subjectid: 8093', 'subjectid: 4058', 'subjectid: DSMT 23', 'subjectid: 11ETK', 'subjectid: 4010', 'subjectid: 4065', 'subjectid: DSMT 24', 'subjectid: 08ACN', 'subjectid: 4046', 'subjectid: 8004', 'subjectid: 8012', 'subjectid: 8028', 'subjectid: 8046', 'subjectid: 8095', 'subjectid: GUJ', 'subjectid: 4069', 'subjectid: DSMT 25', 'subjectid: 12AEY', 'subjectid: 8074', 'subjectid: 4074', 'subjectid: DSMT 28', 'subjectid: 02AET'], \n",
    "        3: ['age (yrs): 21', 'age (yrs): 22', 'age (yrs): 83', 'age (yrs): 77', 'age (yrs): 85', 'age (yrs): 79', 'age (yrs): 74', 'age (yrs): 72', 'age (yrs): 73', 'age (yrs): 93', 'age (yrs): 66', 'age (yrs): 18', 'age (yrs): 23', 'age (yrs): 87', 'age (yrs): 89', 'age (yrs): 81', 'age (yrs): 91', 'age (yrs): 84', 'age (yrs): 80', 'age (yrs): 90', 'age (yrs): 25', 'age (yrs): 96', 'age (yrs): 26', 'age (yrs): 19', 'age (yrs): 76', 'age (yrs): 78', 'age (yrs): 86', 'age (yrs): 68', 'age (yrs): 67', 'age (yrs): 75'], \n",
    "        4: ['height (m): 1.94', 'height (m): 1.84', 'height (m): 1.63', 'height (m): 1.76', 'height (m): 1.66', 'height (m): 1.56', 'height (m): 1.86', 'height (m): 1.59', 'height (m): 1.77', 'height (m): 1.90', 'height (m): 1.69', 'weight (kg): 119.00', 'weight (kg): 86.40', 'weight (kg): 81.00', 'weight (kg): 85.80', 'weight (kg): 72.60', 'height (m): 1.68', 'height (m): 1.97', 'height (m): 1.72', 'height (m): 1.74', 'height (m): 1.58', 'height (m): 1.55', 'height (m): 1.78', 'height (m): 1.73', 'weight (kg): 90.60', 'weight (kg): 56.80', 'weight (kg): 80.40', 'weight (kg): 52.40', 'weight (kg): 89.40', 'weight (kg): 69.90'], \n",
    "        5: ['weight (kg): 94.40', 'weight (kg): 68.20', 'weight (kg): 62.00', 'weight (kg): 115.60', 'weight (kg): 86.60', 'weight (kg): 79.80', 'weight (kg): 82.60', 'weight (kg): 83.60', 'weight (kg): 80.80', 'weight (kg): 78.20', 'weight (kg): 105.00', 'weight (kg): 82.20', 'weight (kg): 72.40', 'bmi (kg/m2): 38.40', 'bmi (kg/m2): 31.40', 'bmi (kg/m2): 33.10', 'bmi (kg/m2): 31.10', 'bmi (kg/m2): 23.50', 'bmi (kg/m2): 28.60', 'weight (kg): 69.60', 'weight (kg): 75.10', 'weight (kg): 67.20', 'weight (kg): 74.00', 'weight (kg): 87.60', 'weight (kg): 58.60', 'weight (kg): 77.40', 'weight (kg): 51.60', 'weight (kg): 88.80', 'weight (kg): 70.80', 'weight (kg): 95.00'],\n",
    "        6: ['bmi (kg/m2): 25.08', 'bmi (kg/m2): 20.10', 'bmi (kg/m2): 23.34', 'bmi (kg/m2): 37.30',\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c26eac",
   "metadata": {},
   "source": [
    "### Step 3: Dataset Analysis and Clinical Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's first import the necessary libraries and examine the available data\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Callable, Optional, Dict, Any\n",
    "\n",
    "# Let's check what files are available in the cohort directory\n",
    "try:\n",
    "    files = os.listdir(in_cohort_dir)\n",
    "    print(f\"Files in directory: {files}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing directory: {e}\")\n",
    "    files = []\n",
    "\n",
    "# Check for gene expression data by looking for large matrix files\n",
    "is_gene_available = False\n",
    "for file in files:\n",
    "    file_path = os.path.join(in_cohort_dir, file)\n",
    "    if file.endswith('.txt') or file.endswith('.csv'):\n",
    "        try:\n",
    "            # Check file size - gene expression files are typically large\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "            if file_size > 1:  # If file is larger than 1MB, it might contain gene expression data\n",
    "                is_gene_available = True\n",
    "                print(f\"Potential gene expression data found in: {file} (Size: {file_size:.2f} MB)\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking file {file}: {e}\")\n",
    "\n",
    "# Try to load sample characteristics\n",
    "sample_characteristics = {}\n",
    "for file in files:\n",
    "    if 'characteristics' in file.lower() and file.endswith('.json'):\n",
    "        try:\n",
    "            with open(os.path.join(in_cohort_dir, file), 'r') as f:\n",
    "                sample_characteristics = json.load(f)\n",
    "                print(f\"Loaded sample characteristics from: {file}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample characteristics from {file}: {e}\")\n",
    "\n",
    "# Try to load background information\n",
    "background_info = {}\n",
    "for file in files:\n",
    "    if 'background' in file.lower() and file.endswith('.json'):\n",
    "        try:\n",
    "            with open(os.path.join(in_cohort_dir, file), 'r') as f:\n",
    "                background_info = json.load(f)\n",
    "                print(f\"Loaded background information from: {file}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading background information from {file}: {e}\")\n",
    "\n",
    "# Analyze what we have\n",
    "print(\"Background Information:\")\n",
    "print(background_info)\n",
    "print(\"\\nSample Characteristics:\")\n",
    "print(sample_characteristics)\n",
    "\n",
    "# Determine if trait, age, and gender data are available\n",
    "trait_row = None\n",
    "age_row = None\n",
    "gender_row = None\n",
    "\n",
    "if sample_characteristics:\n",
    "    print(\"\\nUnique values for each key in sample_characteristics:\")\n",
    "    for key, values in sample_characteristics.items():\n",
    "        unique_values = set(values)\n",
    "        print(f\"Key {key}: {unique_values}\")\n",
    "        \n",
    "        # Look for height information in the values\n",
    "        if any('height' in str(v).lower() for v in unique_values) or any('tall' in str(v).lower() for v in unique_values):\n",
    "            trait_row = key\n",
    "        \n",
    "        # Look for age information\n",
    "        if any('age' in str(v).lower() for v in unique_values) or any('years' in str(v).lower() for v in unique_values):\n",
    "            age_row = key\n",
    "        \n",
    "        # Look for gender information\n",
    "        if any('gender' in str(v).lower() for v in unique_values) or any('sex' in str(v).lower() for v in unique_values) or any('male' in str(v).lower() for v in unique_values) or any('female' in str(v).lower() for v in unique_values):\n",
    "            gender_row = key\n",
    "else:\n",
    "    print(\"No sample characteristics data available to analyze.\")\n",
    "\n",
    "# Define conversion functions\n",
    "def convert_trait(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    if ':' in str(value):\n",
    "        value = value.split(':', 1)[1].strip()\n",
    "    \n",
    "    try:\n",
    "        # Try to convert to float for height (assuming in cm or inches)\n",
    "        return float(value)\n",
    "    except:\n",
    "        # If conversion fails, try to extract numeric values\n",
    "        import re\n",
    "        numeric_value = re.search(r'(\\d+\\.?\\d*)', str(value))\n",
    "        if numeric_value:\n",
    "            return float(numeric_value.group(1))\n",
    "        return None\n",
    "\n",
    "def convert_age(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    if ':' in str(value):\n",
    "        value = value.split(':', 1)[1].strip()\n",
    "    \n",
    "    try:\n",
    "        # Try to convert to float for age (assuming in years)\n",
    "        return float(value)\n",
    "    except:\n",
    "        # If conversion fails, try to extract numeric values\n",
    "        import re\n",
    "        numeric_value = re.search(r'(\\d+\\.?\\d*)', str(value))\n",
    "        if numeric_value:\n",
    "            return float(numeric_value.group(1))\n",
    "        return None\n",
    "\n",
    "def convert_gender(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    if ':' in str(value):\n",
    "        value = value.split(':', 1)[1].strip().lower()\n",
    "    else:\n",
    "        value = str(value).lower()\n",
    "    \n",
    "    if 'female' in value or 'f' == value:\n",
    "        return 0\n",
    "    elif 'male' in value or 'm' == value:\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Check if trait data is available\n",
    "is_trait_available = trait_row is not None\n",
    "print(f\"\\nData availability assessment:\")\n",
    "print(f\"Gene expression data available: {is_gene_available}\")\n",
    "print(f\"Trait (Height) data available: {is_trait_available}\")\n",
    "print(f\"Age data available: {age_row is not None}\")\n",
    "print(f\"Gender data available: {gender_row is not None}\")\n",
    "\n",
    "# Validate and save cohort information\n",
    "initial_validation = validate_and_save_cohort_info(\n",
    "    is_final=False,\n",
    "    cohort=cohort,\n",
    "    info_path=json_path,\n",
    "    is_gene_available=is_gene_available,\n",
    "    is_trait_available=is_trait_available\n",
    ")\n",
    "\n",
    "# Extract clinical features if trait data is available\n",
    "if is_trait_available:\n",
    "    try:\n",
    "        # Create a dataframe from sample_characteristics\n",
    "        clinical_df = pd.DataFrame(sample_characteristics)\n",
    "        \n",
    "        # Use the geo_select_clinical_features function to extract clinical features\n",
    "        selected_clinical_df = geo_select_clinical_features(\n",
    "            clinical_df=clinical_df,\n",
    "            trait=trait,\n",
    "            trait_row=trait_row,\n",
    "            convert_trait=convert_trait,\n",
    "            age_row=age_row,\n",
    "            convert_age=convert_age if age_row is not None else None,\n",
    "            gender_row=gender_row,\n",
    "            convert_gender=convert_gender if gender_row is not None else None\n",
    "        )\n",
    "        \n",
    "        # Preview the dataframe\n",
    "        print(\"\\nClinical Features Preview:\")\n",
    "        print(preview_df(selected_clinical_df))\n",
    "        \n",
    "        # Save the clinical data to a CSV file\n",
    "        os.makedirs(os.path.dirname(out_clinical_data_file), exist_ok=True)\n",
    "        selected_clinical_df.to_csv(out_clinical_data_file, index=False)\n",
    "        print(f\"Clinical data saved to: {out_clinical_data_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing clinical data: {e}\")\n",
    "else:\n",
    "    print(\"Skipping clinical feature extraction as trait data is not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89002d02",
   "metadata": {},
   "source": [
    "### Step 4: Gene Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the file paths for the SOFT file and matrix file\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "\n",
    "# 2. First, let's examine the structure of the matrix file to understand its format\n",
    "import gzip\n",
    "\n",
    "# Peek at the first few lines of the file to understand its structure\n",
    "with gzip.open(matrix_file, 'rt') as file:\n",
    "    # Read first 100 lines to find the header structure\n",
    "    for i, line in enumerate(file):\n",
    "        if '!series_matrix_table_begin' in line:\n",
    "            print(f\"Found data marker at line {i}\")\n",
    "            # Read the next line which should be the header\n",
    "            header_line = next(file)\n",
    "            print(f\"Header line: {header_line.strip()}\")\n",
    "            # And the first data line\n",
    "            first_data_line = next(file)\n",
    "            print(f\"First data line: {first_data_line.strip()}\")\n",
    "            break\n",
    "        if i > 100:  # Limit search to first 100 lines\n",
    "            print(\"Matrix table marker not found in first 100 lines\")\n",
    "            break\n",
    "\n",
    "# 3. Now try to get the genetic data with better error handling\n",
    "try:\n",
    "    gene_data = get_genetic_data(matrix_file)\n",
    "    print(gene_data.index[:20])\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "    \n",
    "    # Alternative approach: manually extract the data\n",
    "    print(\"\\nTrying alternative approach to read the gene data:\")\n",
    "    with gzip.open(matrix_file, 'rt') as file:\n",
    "        # Find the start of the data\n",
    "        for line in file:\n",
    "            if '!series_matrix_table_begin' in line:\n",
    "                break\n",
    "                \n",
    "        # Read the headers and data\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(file, sep='\\t', index_col=0)\n",
    "        print(f\"Column names: {df.columns[:5]}\")\n",
    "        print(f\"First 20 row IDs: {df.index[:20]}\")\n",
    "        gene_data = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039700ca",
   "metadata": {},
   "source": [
    "### Step 5: Gene Identifier Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf2ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the gene identifiers in the gene expression data\n",
    "\n",
    "# Examples from the data:\n",
    "# - \"100009676_at\"\n",
    "# - \"10000_at\"\n",
    "# - \"10001_at\"\n",
    "\n",
    "# These appear to be probe IDs from a microarray platform, not standard human gene symbols\n",
    "# Standard human gene symbols would be like BRCA1, TP53, etc.\n",
    "# The \"_at\" suffix is characteristic of Affymetrix microarray probe IDs\n",
    "# These identifiers will need to be mapped to standard gene symbols for analysis\n",
    "\n",
    "requires_gene_mapping = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ade383",
   "metadata": {},
   "source": [
    "### Step 6: Gene Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73984a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's first examine the structure of the SOFT file before trying to parse it\n",
    "import gzip\n",
    "\n",
    "# Look at the first few lines of the SOFT file to understand its structure\n",
    "print(\"Examining SOFT file structure:\")\n",
    "try:\n",
    "    with gzip.open(soft_file, 'rt') as file:\n",
    "        # Read first 20 lines to understand the file structure\n",
    "        for i, line in enumerate(file):\n",
    "            if i < 20:\n",
    "                print(f\"Line {i}: {line.strip()}\")\n",
    "            else:\n",
    "                break\n",
    "except Exception as e:\n",
    "    print(f\"Error reading SOFT file: {e}\")\n",
    "\n",
    "# 2. Now let's try a more robust approach to extract the gene annotation\n",
    "# Instead of using the library function which failed, we'll implement a custom approach\n",
    "try:\n",
    "    # First, look for the platform section which contains gene annotation\n",
    "    platform_data = []\n",
    "    with gzip.open(soft_file, 'rt') as file:\n",
    "        in_platform_section = False\n",
    "        for line in file:\n",
    "            if line.startswith('^PLATFORM'):\n",
    "                in_platform_section = True\n",
    "                continue\n",
    "            if in_platform_section and line.startswith('!platform_table_begin'):\n",
    "                # Next line should be the header\n",
    "                header = next(file).strip()\n",
    "                platform_data.append(header)\n",
    "                # Read until the end of the platform table\n",
    "                for table_line in file:\n",
    "                    if table_line.startswith('!platform_table_end'):\n",
    "                        break\n",
    "                    platform_data.append(table_line.strip())\n",
    "                break\n",
    "    \n",
    "    # If we found platform data, convert it to a DataFrame\n",
    "    if platform_data:\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        platform_text = '\\n'.join(platform_data)\n",
    "        gene_annotation = pd.read_csv(io.StringIO(platform_text), delimiter='\\t', \n",
    "                                      low_memory=False, on_bad_lines='skip')\n",
    "        print(\"\\nGene annotation preview:\")\n",
    "        print(preview_df(gene_annotation))\n",
    "    else:\n",
    "        print(\"Could not find platform table in SOFT file\")\n",
    "        \n",
    "        # Try an alternative approach - extract mapping from other sections\n",
    "        with gzip.open(soft_file, 'rt') as file:\n",
    "            for line in file:\n",
    "                if 'ANNOTATION information' in line or 'annotation information' in line:\n",
    "                    print(f\"Found annotation information: {line.strip()}\")\n",
    "                if line.startswith('!Platform_title') or line.startswith('!platform_title'):\n",
    "                    print(f\"Platform title: {line.strip()}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error processing gene annotation: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71e50d",
   "metadata": {},
   "source": [
    "### Step 7: Gene Identifier Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e93cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract gene annotation data from the SOFT file using custom approach\n",
    "# Let's extract the gene annotation data using get_gene_annotation\n",
    "gene_annotation = get_gene_annotation(soft_file)\n",
    "\n",
    "# Identify the columns we need for mapping\n",
    "# Looking at the gene expression data, we have IDs like \"100009676_at\"\n",
    "# In the gene annotation, we see \"ID\" column has similar identifiers (e.g., \"1_at\")\n",
    "# The \"Description\" column appears to have gene names/descriptions\n",
    "\n",
    "# Get the mapping between probe IDs and gene descriptions\n",
    "mapping_df = get_gene_mapping(gene_annotation, 'ID', 'Description')\n",
    "\n",
    "# Print mapping information for verification\n",
    "print(f\"Found {len(mapping_df)} probe-to-gene mappings\")\n",
    "print(f\"Sample mappings (first 5 rows):\")\n",
    "print(mapping_df.head())\n",
    "\n",
    "# Now apply the gene mapping to convert probe measurements to gene expression\n",
    "gene_data = apply_gene_mapping(gene_data, mapping_df)\n",
    "\n",
    "# Print information about the resulting gene expression data\n",
    "print(f\"\\nAfter mapping: gene expression data has {gene_data.shape[0]} genes and {gene_data.shape[1]} samples\")\n",
    "print(\"First 5 genes:\")\n",
    "print(gene_data.head())\n",
    "\n",
    "# Save the gene expression data to a CSV file\n",
    "os.makedirs(os.path.dirname(out_gene_data_file), exist_ok=True)\n",
    "gene_data.to_csv(out_gene_data_file)\n",
    "print(f\"Gene expression data saved to: {out_gene_data_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfbae0",
   "metadata": {},
   "source": [
    "### Step 8: Data Normalization and Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c411a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths first\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "\n",
    "# 1. Let's correctly read the clinical data first to extract height information\n",
    "background_prefixes = ['!Series_title', '!Series_summary', '!Series_overall_design']\n",
    "clinical_prefixes = ['!Sample_geo_accession', '!Sample_characteristics_ch1']\n",
    "background_info, clinical_data = get_background_and_clinical_data(matrix_file, background_prefixes, clinical_prefixes)\n",
    "\n",
    "# Inspect the clinical data to find height information\n",
    "sample_characteristics_dict = get_unique_values_by_row(clinical_data)\n",
    "\n",
    "# Based on the sample_characteristics_dict from Step 1, height data is in row 4\n",
    "# Let's extract height and other clinical information\n",
    "trait_row = 4  # Height information\n",
    "age_row = 3    # Age information \n",
    "gender_row = 1 # Gender information (Sex: M/F)\n",
    "\n",
    "# Define conversion functions\n",
    "def convert_trait(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # Extract the height value after the colon\n",
    "        if \"height (m):\" in value:\n",
    "            height_str = value.split(\"height (m):\")[1].strip()\n",
    "            return float(height_str)\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def convert_age(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # Extract the age value after the colon\n",
    "        age_str = value.split(\"age (yrs):\")[1].strip()\n",
    "        return float(age_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def convert_gender(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    # Convert 'Sex: F' to 0 and 'Sex: M' to 1\n",
    "    if \"Sex: F\" in value:\n",
    "        return 0\n",
    "    elif \"Sex: M\" in value:\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Extract clinical features including height\n",
    "clinical_features = geo_select_clinical_features(\n",
    "    clinical_data, \n",
    "    trait=trait, \n",
    "    trait_row=trait_row,\n",
    "    convert_trait=convert_trait,\n",
    "    age_row=age_row,\n",
    "    convert_age=convert_age,\n",
    "    gender_row=gender_row,\n",
    "    convert_gender=convert_gender\n",
    ")\n",
    "\n",
    "# Save the clinical data\n",
    "os.makedirs(os.path.dirname(out_clinical_data_file), exist_ok=True)\n",
    "clinical_features.to_csv(out_clinical_data_file)\n",
    "print(f\"Clinical data saved to {out_clinical_data_file}\")\n",
    "print(f\"Clinical data shape: {clinical_features.shape}\")\n",
    "print(f\"Clinical data preview:\")\n",
    "print(clinical_features.head())\n",
    "\n",
    "# Now extract gene expression data\n",
    "# 1. Extract gene expression data using the get_genetic_data function\n",
    "gene_data = get_genetic_data(matrix_file)\n",
    "print(f\"Gene data shape before normalization: {gene_data.shape}\")\n",
    "\n",
    "# 2. Normalize gene symbols using the NCBI Gene database\n",
    "# If normalization results in empty data, use the original data as a fallback\n",
    "try:\n",
    "    normalized_gene_data = normalize_gene_symbols_in_index(gene_data)\n",
    "    print(f\"Gene data shape after normalization: {normalized_gene_data.shape}\")\n",
    "    \n",
    "    # Check if we lost all genes during normalization and use fallback if needed\n",
    "    if normalized_gene_data.empty:\n",
    "        print(\"Warning: All genes were filtered out during normalization. Using fallback approach.\")\n",
    "        # Fallback: Use original data with the 'at' suffixes stripped\n",
    "        gene_data.index = gene_data.index.str.split('_').str[0]\n",
    "        normalized_gene_data = gene_data.groupby(gene_data.index).mean()\n",
    "        print(f\"Fallback gene data shape: {normalized_gene_data.shape}\")\n",
    "    \n",
    "    # Save the normalized gene data\n",
    "    os.makedirs(os.path.dirname(out_gene_data_file), exist_ok=True)\n",
    "    normalized_gene_data.to_csv(out_gene_data_file)\n",
    "    print(f\"Gene data saved to {out_gene_data_file}\")\n",
    "    \n",
    "    is_gene_available = True\n",
    "except Exception as e:\n",
    "    print(f\"Error normalizing gene data: {e}\")\n",
    "    is_gene_available = False\n",
    "    normalized_gene_data = gene_data  # Use original data if normalization fails\n",
    "\n",
    "# 3. Link clinical and genetic data - transform gene data to have samples as rows\n",
    "if is_gene_available and normalized_gene_data is not None:\n",
    "    # Transpose normalized_gene_data to have samples as rows\n",
    "    gene_data_t = normalized_gene_data.T\n",
    "    \n",
    "    # Create linked data - we need to ensure sample IDs align\n",
    "    # Note: We link based on sample IDs, which should be in the columns of normalized_gene_data\n",
    "    # and the index of clinical_features.T\n",
    "    linked_data = pd.concat([clinical_features.T, gene_data_t], axis=1)\n",
    "    print(f\"Linked data shape: {linked_data.shape}\")\n",
    "    \n",
    "    # Check for the completeness of the trait data\n",
    "    trait_available = linked_data[trait].notna().sum() > 0\n",
    "    print(f\"Number of samples with {trait} data: {linked_data[trait].notna().sum()}\")\n",
    "    \n",
    "    # Handle missing values\n",
    "    if trait_available:\n",
    "        linked_data = handle_missing_values(linked_data, trait)\n",
    "        print(f\"After handling missing values, linked data shape: {linked_data.shape}\")\n",
    "        \n",
    "        # Check for trait bias\n",
    "        is_trait_available = True\n",
    "        is_biased, linked_data = judge_and_remove_biased_features(linked_data, trait)\n",
    "        \n",
    "        note = \"Dataset contains both gene expression and height data.\"\n",
    "    else:\n",
    "        is_trait_available = False\n",
    "        is_biased = False\n",
    "        note = \"Dataset does not contain sufficient height measurements for analysis.\"\n",
    "else:\n",
    "    # Create a minimal dataframe with just the trait column\n",
    "    linked_data = clinical_features.T\n",
    "    is_trait_available = linked_data[trait].notna().sum() > 0\n",
    "    is_biased = False\n",
    "    is_gene_available = False\n",
    "    note = \"Dataset does not contain usable gene expression data.\"\n",
    "\n",
    "# 4 & 5. Validate and save cohort information\n",
    "is_usable = validate_and_save_cohort_info(\n",
    "    is_final=True, \n",
    "    cohort=cohort, \n",
    "    info_path=json_path, \n",
    "    is_gene_available=is_gene_available, \n",
    "    is_trait_available=is_trait_available, \n",
    "    is_biased=is_biased,\n",
    "    df=linked_data,\n",
    "    note=note\n",
    ")\n",
    "\n",
    "# 6. Save linked data if usable\n",
    "print(f\"Dataset usability: {is_usable}\")\n",
    "if is_usable:\n",
    "    os.makedirs(os.path.dirname(out_data_file), exist_ok=True)\n",
    "    linked_data.to_csv(out_data_file)\n",
    "    print(f\"Linked data saved to {out_data_file}\")\n",
    "else:\n",
    "    print(f\"Dataset is not suitable for {trait} association studies.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ecee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "# Path Configuration\n",
    "from tools.preprocess import *\n",
    "\n",
    "# Processing context\n",
    "trait = \"Glucocorticoid_Sensitivity\"\n",
    "cohort = \"GSE65645\"\n",
    "\n",
    "# Input paths\n",
    "in_trait_dir = \"../../input/GEO/Glucocorticoid_Sensitivity\"\n",
    "in_cohort_dir = \"../../input/GEO/Glucocorticoid_Sensitivity/GSE65645\"\n",
    "\n",
    "# Output paths\n",
    "out_data_file = \"../../output/preprocess/Glucocorticoid_Sensitivity/GSE65645.csv\"\n",
    "out_gene_data_file = \"../../output/preprocess/Glucocorticoid_Sensitivity/gene_data/GSE65645.csv\"\n",
    "out_clinical_data_file = \"../../output/preprocess/Glucocorticoid_Sensitivity/clinical_data/GSE65645.csv\"\n",
    "json_path = \"../../output/preprocess/Glucocorticoid_Sensitivity/cohort_info.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81885d",
   "metadata": {},
   "source": [
    "### Step 1: Initial Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a95b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.preprocess import *\n",
    "# 1. Identify the paths to the SOFT file and the matrix file\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "\n",
    "# 2. Read the matrix file to obtain background information and sample characteristics data\n",
    "background_prefixes = ['!Series_title', '!Series_summary', '!Series_overall_design']\n",
    "clinical_prefixes = ['!Sample_geo_accession', '!Sample_characteristics_ch1']\n",
    "background_info, clinical_data = get_background_and_clinical_data(matrix_file, background_prefixes, clinical_prefixes)\n",
    "\n",
    "# 3. Obtain the sample characteristics dictionary from the clinical dataframe\n",
    "sample_characteristics_dict = get_unique_values_by_row(clinical_data)\n",
    "\n",
    "# 4. Explicitly print out all the background information and the sample characteristics dictionary\n",
    "print(\"Background Information:\")\n",
    "print(background_info)\n",
    "print(\"Sample Characteristics Dictionary:\")\n",
    "print(sample_characteristics_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ea8be",
   "metadata": {},
   "source": [
    "### Step 2: Dataset Analysis and Clinical Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Optional, Callable, Dict, Any, List\n",
    "\n",
    "# 1. Gene Expression Data Availability\n",
    "# Looking at the background info, this is an Agilent microarray with lncRNA expression data\n",
    "# It's likely to contain gene expression data, though focused on lncRNAs\n",
    "is_gene_available = True\n",
    "\n",
    "# 2. Variable Availability and Data Type Conversion\n",
    "# 2.1 Data Availability\n",
    "\n",
    "# For trait (Glucocorticoid_Sensitivity)\n",
    "# Looking at the background info, this study involves responsiveness to prednisolone/prednisone (glucocorticoids)\n",
    "# From the sample characteristics dictionary, we can use the 'translocation' information as it relates to \n",
    "# glucocorticoid sensitivity in B-ALL\n",
    "trait_row = 1  # corresponds to the translocation types\n",
    "\n",
    "# For age and gender\n",
    "# These are not available in the sample characteristics dictionary\n",
    "age_row = None\n",
    "gender_row = None\n",
    "\n",
    "# 2.2 Data Type Conversion\n",
    "\n",
    "def convert_trait(value: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Convert translocation types to binary for glucocorticoid sensitivity.\n",
    "    \n",
    "    Based on the background information, MLL translocations are associated with \n",
    "    poorer response to glucocorticoids, so we'll use this as the binary indicator.\n",
    "    0 = TEL_AML1 or E2A_PBX1 (better glucocorticoid response)\n",
    "    1 = MLL (worse glucocorticoid response)\n",
    "    \"\"\"\n",
    "    if not value or ':' not in value:\n",
    "        return None\n",
    "    \n",
    "    translocation = value.split(':', 1)[1].strip()\n",
    "    \n",
    "    if translocation == 'MLL':\n",
    "        return 1  # Less sensitive to glucocorticoids\n",
    "    elif translocation in ['TEL_AML1', 'E2A_PBX1']:\n",
    "        return 0  # More sensitive to glucocorticoids\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def convert_age(value: str) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Placeholder function for age conversion (not used as age data is not available).\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "def convert_gender(value: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Placeholder function for gender conversion (not used as gender data is not available).\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "# 3. Save Metadata\n",
    "# Determine if trait data is available\n",
    "is_trait_available = trait_row is not None\n",
    "\n",
    "# Save initial metadata\n",
    "validate_and_save_cohort_info(\n",
    "    is_final=False,\n",
    "    cohort=cohort,\n",
    "    info_path=json_path,\n",
    "    is_gene_available=is_gene_available,\n",
    "    is_trait_available=is_trait_available\n",
    ")\n",
    "\n",
    "# 4. Clinical Feature Extraction\n",
    "if trait_row is not None:\n",
    "    # Assuming the clinical data is stored somewhere and accessible\n",
    "    # We'll create a properly formatted DataFrame based on the sample characteristics\n",
    "    \n",
    "    # First, create columns for samples\n",
    "    sample_chars = {0: ['sample_type: bone marrow'], 1: ['translocation: TEL_AML1', 'translocation: E2A_PBX1', 'translocation: MLL']}\n",
    "    \n",
    "    # The format expected by geo_select_clinical_features seems to be:\n",
    "    # - Rows represent different characteristics (like sample_type, translocation)\n",
    "    # - Columns represent different samples\n",
    "    \n",
    "    # Create a DataFrame with sample names as columns\n",
    "    num_samples = max(len(values) for values in sample_chars.values())\n",
    "    sample_columns = [f'Sample_{i+1}' for i in range(num_samples)]\n",
    "    \n",
    "    clinical_data = pd.DataFrame(index=sample_chars.keys(), columns=sample_columns)\n",
    "    \n",
    "    # Fill in the data\n",
    "    for row_idx, values in sample_chars.items():\n",
    "        for sample_idx, value in enumerate(values):\n",
    "            if sample_idx < len(sample_columns):\n",
    "                clinical_data.iloc[row_idx, sample_idx] = value\n",
    "    \n",
    "    # Extract clinical features\n",
    "    selected_clinical_df = geo_select_clinical_features(\n",
    "        clinical_df=clinical_data,\n",
    "        trait=trait,\n",
    "        trait_row=trait_row,\n",
    "        convert_trait=convert_trait,\n",
    "        age_row=age_row,\n",
    "        convert_age=convert_age,\n",
    "        gender_row=gender_row,\n",
    "        convert_gender=convert_gender\n",
    "    )\n",
    "    \n",
    "    # Preview the DataFrame\n",
    "    preview = preview_df(selected_clinical_df)\n",
    "    print(\"Preview of selected clinical features:\")\n",
    "    print(preview)\n",
    "    \n",
    "    # Save the clinical data\n",
    "    os.makedirs(os.path.dirname(out_clinical_data_file), exist_ok=True)\n",
    "    selected_clinical_df.to_csv(out_clinical_data_file)\n",
    "    print(f\"Clinical data saved to {out_clinical_data_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58f751",
   "metadata": {},
   "source": [
    "### Step 3: Gene Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b89df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the file paths for the SOFT file and matrix file\n",
    "soft_file, matrix_file = geo_get_relevant_filepaths(in_cohort_dir)\n",
    "\n",
    "# 2. First, let's examine the structure of the matrix file to understand its format\n",
    "import gzip\n",
    "\n",
    "# Peek at the first few lines of the file to understand its structure\n",
    "with gzip.open(matrix_file, 'rt') as file:\n",
    "    # Read first 100 lines to find the header structure\n",
    "    for i, line in enumerate(file):\n",
    "        if '!series_matrix_table_begin' in line:\n",
    "            print(f\"Found data marker at line {i}\")\n",
    "            # Read the next line which should be the header\n",
    "            header_line = next(file)\n",
    "            print(f\"Header line: {header_line.strip()}\")\n",
    "            # And the first data line\n",
    "            first_data_line = next(file)\n",
    "            print(f\"First data line: {first_data_line.strip()}\")\n",
    "            break\n",
    "        if i > 100:  # Limit search to first 100 lines\n",
    "            print(\"Matrix table marker not found in first 100 lines\")\n",
    "            break\n",
    "\n",
    "# 3. Now try to get the genetic data with better error handling\n",
    "try:\n",
    "    gene_data = get_genetic_data(matrix_file)\n",
    "    print(gene_data.index[:20])\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "    \n",
    "    # Alternative approach: manually extract the data\n",
    "    print(\"\\nTrying alternative approach to read the gene data:\")\n",
    "    with gzip.open(matrix_file, 'rt') as file:\n",
    "        # Find the start of the data\n",
    "        for line in file:\n",
    "            if '!series_matrix_table_begin' in line:\n",
    "                break\n",
    "                \n",
    "        # Read the headers and data\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(file, sep='\\t', index_col=0)\n",
    "        print(f\"Column names: {df.columns[:5]}\")\n",
    "        print(f\"First 20 row IDs: {df.index[:20]}\")\n",
    "        gene_data = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f35137e",
   "metadata": {},
   "source": [
    "### Step 4: Gene Identifier Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a6e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the gene identifiers shown in the sample data, these appear to be Agilent microarray\n",
    "# probe IDs (starting with A_19_P) mixed with control probes. These are not standard human\n",
    "# gene symbols and will require mapping to convert to gene symbols.\n",
    "\n",
    "requires_gene_mapping = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f53c57",
   "metadata": {},
   "source": [
    "### Step 5: Gene Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a9b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's first examine the structure of the SOFT file before trying to parse it\n",
    "import gzip\n",
    "\n",
    "# Look at the first few lines of the SOFT file to understand its structure\n",
    "print(\"Examining SOFT file structure:\")\n",
    "try:\n",
    "    with gzip.open(soft_file, 'rt') as file:\n",
    "        # Read first 20 lines to understand the file structure\n",
    "        for i, line in enumerate(file):\n",
    "            if i < 20:\n",
    "                print(f\"Line {i}: {line.strip()}\")\n",
    "            else:\n",
    "                break\n",
    "except Exception as e:\n",
    "    print(f\"Error reading SOFT file: {e}\")\n",
    "\n",
    "# 2. Now let's try a more robust approach to extract the gene annotation\n",
    "# Instead of using the library function which failed, we'll implement a custom approach\n",
    "try:\n",
    "    # First, look for the platform section which contains gene annotation\n",
    "    platform_data = []\n",
    "    with gzip.open(soft_file, 'rt') as file:\n",
    "        in_platform_section = False\n",
    "        for line in file:\n",
    "            if line.startswith('^PLATFORM'):\n",
    "                in_platform_section = True\n",
    "                continue\n",
    "            if in_platform_section and line.startswith('!platform_table_begin'):\n",
    "                # Next line should be the header\n",
    "                header = next(file).strip()\n",
    "                platform_data.append(header)\n",
    "                # Read until the end of the platform table\n",
    "                for table_line in file:\n",
    "                    if table_line.startswith('!platform_table_end'):\n",
    "                        break\n",
    "                    platform_data.append(table_line.strip())\n",
    "                break\n",
    "    \n",
    "    # If we found platform data, convert it to a DataFrame\n",
    "    if platform_data:\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        platform_text = '\\n'.join(platform_data)\n",
    "        gene_annotation = pd.read_csv(io.StringIO(platform_text), delimiter='\\t', \n",
    "                                      low_memory=False, on_bad_lines='skip')\n",
    "        print(\"\\nGene annotation preview:\")\n",
    "        print(preview_df(gene_annotation))\n",
    "    else:\n",
    "        print(\"Could not find platform table in SOFT file\")\n",
    "        \n",
    "        # Try an alternative approach - extract mapping from other sections\n",
    "        with gzip.open(soft_file, 'rt') as file:\n",
    "            for line in file:\n",
    "                if 'ANNOTATION information' in line or 'annotation information' in line:\n",
    "                    print(f\"Found annotation information: {line.strip()}\")\n",
    "                if line.startswith('!Platform_title') or line.startswith('!platform_title'):\n",
    "                    print(f\"Platform title: {line.strip()}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error processing gene annotation: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feaf095",
   "metadata": {},
   "source": [
    "### Step 6: Gene Identifier Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d2520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Determine which keys to use for mapping\n",
    "# From the outputs, we can see:\n",
    "# - The gene expression data uses 'ID' as identifiers\n",
    "# - In the annotation dataframe, 'ID' corresponds to probe IDs and 'GENE_SYMBOL' contains gene symbols\n",
    "\n",
    "# 2. Get gene mapping dataframe\n",
    "gene_mapping_df = get_gene_mapping(gene_annotation, prob_col='ID', gene_col='GENE_SYMBOL')\n",
    "\n",
    "# 3. Apply gene mapping to convert probe-level measurements to gene expression\n",
    "# First, let's check if there are any rows in the mapping dataframe\n",
    "print(f\"Number of rows in mapping dataframe: {len(gene_mapping_df)}\")\n",
    "print(f\"Sample of gene mapping data (first 5 rows):\")\n",
    "print(gene_mapping_df.head())\n",
    "\n",
    "# Apply the mapping\n",
    "gene_data = apply_gene_mapping(gene_data, gene_mapping_df)\n",
    "\n",
    "# Check the resulting gene expression data\n",
    "print(f\"\\nNumber of genes after mapping: {len(gene_data)}\")\n",
    "print(f\"First few genes:\")\n",
    "print(gene_data.index[:10])\n",
    "\n",
    "# Preview the gene expression data\n",
    "print(\"\\nPreview of gene expression data:\")\n",
    "gene_data_preview = preview_df(gene_data)\n",
    "print(gene_data_preview)\n",
    "\n",
    "# Save the gene expression data\n",
    "os.makedirs(os.path.dirname(out_gene_data_file), exist_ok=True)\n",
    "gene_data.to_csv(out_gene_data_file)\n",
    "print(f\"\\nGene expression data saved to {out_gene_data_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90226d2",
   "metadata": {},
   "source": [
    "### Step 7: Data Normalization and Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalize gene symbols in the obtained gene expression data\n",
    "normalized_gene_data = normalize_gene_symbols_in_index(gene_data)\n",
    "print(f\"Gene data shape after normalization: {normalized_gene_data.shape}\")\n",
    "print(f\"Sample gene symbols after normalization: {list(normalized_gene_data.index[:10])}\")\n",
    "\n",
    "# Save the normalized gene data\n",
    "os.makedirs(os.path.dirname(out_gene_data_file), exist_ok=True)\n",
    "normalized_gene_data.to_csv(out_gene_data_file)\n",
    "print(f\"Gene data saved to {out_gene_data_file}\")\n",
    "\n",
    "# 2. Re-load the clinical data from the SOFT file to extract sample characteristics\n",
    "print(\"\\nExtracting clinical data from SOFT file...\")\n",
    "sample_info = {}\n",
    "\n",
    "# Read the SOFT file to extract sample information\n",
    "with gzip.open(soft_file, 'rt') as f:\n",
    "    current_sample = None\n",
    "    for line in f:\n",
    "        # Detect sample sections\n",
    "        if line.startswith('!Sample_geo_accession'):\n",
    "            sample_id = line.split('=')[1].strip()\n",
    "            current_sample = sample_id\n",
    "            sample_info[current_sample] = {}\n",
    "        \n",
    "        # Extract translocation information\n",
    "        if current_sample and 'translocation' in line.lower():\n",
    "            if 'mll' in line.lower() or 'mil' in line.lower():\n",
    "                sample_info[current_sample]['translocation'] = 'MLL'\n",
    "            elif 'tel' in line.lower() and 'aml' in line.lower():\n",
    "                sample_info[current_sample]['translocation'] = 'TEL_AML1'\n",
    "            elif 'e2a' in line.lower() and 'pbx' in line.lower():\n",
    "                sample_info[current_sample]['translocation'] = 'E2A_PBX1'\n",
    "\n",
    "print(f\"Found information for {len(sample_info)} samples\")\n",
    "\n",
    "# Map samples to trait values based on translocation type\n",
    "clinical_data = {}\n",
    "genetic_sample_ids = normalized_gene_data.columns.tolist()\n",
    "\n",
    "for sample_id in genetic_sample_ids:\n",
    "    if sample_id in sample_info and 'translocation' in sample_info[sample_id]:\n",
    "        translocation = sample_info[sample_id]['translocation']\n",
    "        if translocation == 'MLL':\n",
    "            clinical_data[sample_id] = 1  # Less sensitive to glucocorticoids\n",
    "        elif translocation in ['TEL_AML1', 'E2A_PBX1']:\n",
    "            clinical_data[sample_id] = 0  # More sensitive to glucocorticoids\n",
    "    else:\n",
    "        clinical_data[sample_id] = None\n",
    "\n",
    "# Create clinical dataframe\n",
    "clinical_df = pd.DataFrame({trait: clinical_data}, index=genetic_sample_ids)\n",
    "print(f\"Clinical data shape: {clinical_df.shape}\")\n",
    "print(\"Clinical data preview:\")\n",
    "print(clinical_df.head())\n",
    "print(f\"Samples with valid trait values: {clinical_df[trait].notna().sum()}\")\n",
    "\n",
    "# Save updated clinical data\n",
    "os.makedirs(os.path.dirname(out_clinical_data_file), exist_ok=True)\n",
    "clinical_df.to_csv(out_clinical_data_file)\n",
    "print(f\"Updated clinical data saved to {out_clinical_data_file}\")\n",
    "\n",
    "# 3. Link clinical and genetic data\n",
    "linked_data = pd.concat([clinical_df, normalized_gene_data.T], axis=1)\n",
    "print(f\"Linked data shape: {linked_data.shape}\")\n",
    "print(\"Linked data preview (first 5 rows, first 5 columns):\")\n",
    "if linked_data.shape[1] >= 5:\n",
    "    print(linked_data.iloc[:5, :5])\n",
    "else:\n",
    "    print(linked_data.head())\n",
    "\n",
    "# 4. Handle missing values\n",
    "print(\"\\nMissing values before handling:\")\n",
    "print(f\"  Trait ({trait}) missing: {linked_data[trait].isna().sum()} out of {len(linked_data)}\")\n",
    "gene_cols = [col for col in linked_data.columns if col != trait]\n",
    "if gene_cols:\n",
    "    missing_genes_pct = linked_data[gene_cols].isna().mean()\n",
    "    genes_with_high_missing = sum(missing_genes_pct > 0.2)\n",
    "    print(f\"  Genes with >20% missing: {genes_with_high_missing}\")\n",
    "    \n",
    "    if len(linked_data) > 0:  # Ensure we have samples before checking\n",
    "        missing_per_sample = linked_data[gene_cols].isna().mean(axis=1)\n",
    "        samples_with_high_missing = sum(missing_per_sample > 0.05)\n",
    "        print(f\"  Samples with >5% missing genes: {samples_with_high_missing}\")\n",
    "\n",
    "# Handle missing values\n",
    "cleaned_data = handle_missing_values(linked_data, trait)\n",
    "print(f\"Data shape after handling missing values: {cleaned_data.shape}\")\n",
    "\n",
    "# 5. Evaluate bias in trait and demographic features\n",
    "if len(cleaned_data) > 0:\n",
    "    trait_biased, cleaned_data = judge_and_remove_biased_features(cleaned_data, trait)\n",
    "else:\n",
    "    trait_biased = True\n",
    "    print(\"Dataset is empty after handling missing values.\")\n",
    "\n",
    "# 6. Final validation and save\n",
    "note = \"Dataset contains gene expression data from B-ALL patients with different translocations. \"\n",
    "note += \"Translocation type is used as a proxy for glucocorticoid sensitivity: MLL translocations have poorer \"\n",
    "note += \"response to glucocorticoids compared to TEL_AML1 or E2A_PBX1 translocations. No demographic features available.\"\n",
    "\n",
    "is_gene_available = len(normalized_gene_data) > 0\n",
    "is_trait_available = len(clinical_df) > 0 and clinical_df[trait].notna().sum() > 0\n",
    "\n",
    "is_usable = validate_and_save_cohort_info(\n",
    "    is_final=True, \n",
    "    cohort=cohort, \n",
    "    info_path=json_path, \n",
    "    is_gene_available=is_gene_available, \n",
    "    is_trait_available=is_trait_available, \n",
    "    is_biased=trait_biased, \n",
    "    df=cleaned_data,\n",
    "    note=note\n",
    ")\n",
    "\n",
    "# 7. Save if usable\n",
    "if is_usable and len(cleaned_data) > 0:\n",
    "    os.makedirs(os.path.dirname(out_data_file), exist_ok=True)\n",
    "    cleaned_data.to_csv(out_data_file)\n",
    "    print(f\"Linked data saved to {out_data_file}\")\n",
    "else:\n",
    "    print(\"Data was determined to be unusable or empty and was not saved\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
